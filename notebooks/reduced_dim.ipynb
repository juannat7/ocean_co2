{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifications\n",
    "\n",
    "Link to Interactive Notebook: \n",
    "https://colab.research.google.com/drive/1sbJTsgCsAQwCkGdLXK7EdgkaTpiTGBM1#scrollTo=T71qxHyh9p23\n",
    "\n",
    "1. Reduced Input Dimension\n",
    "2. Different handling of xco2: merge the value in as an additional input in the fully connected layer (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv/lib/python3.8/site-packages/xarray/backends/cfgrib_.py:27: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n",
      "2021-09-22 16:29:45.504520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#!module load cuda11.0/toolkit cuda11.0/blas cudnn8.0-cuda11.0\n",
    "\n",
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "#tf.config.list_physical_devices()\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from utils import df_to_xarray,read_xarray,plot_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv/lib/python3.8/site-packages/xarray/backends/plugins.py:61: RuntimeWarning: Engine 'cfgrib' loading failed:\n",
      "Cannot find the ecCodes library\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Reading Data\n",
    "dir_name=\"../data/data1\"\n",
    "val_dir_name=\"../data/data2\"\n",
    "\n",
    "\n",
    "chl,mld,sss,sst,u10,fg_co2,xco2,icefrac,patm,pco2=read_xarray(dir_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nan(arr):\n",
    "    nans=np.isnan(arr)\n",
    "    min_val=arr[~nans].min()\n",
    "    #print(min_val)\n",
    "    arr[nans]=min_val-1\n",
    "    return arr\n",
    "\n",
    "def add_dimension(arr):\n",
    "    images=np.expand_dims(arr, axis=3)\n",
    "    return images\n",
    "\n",
    "def scale_image(arr):\n",
    "    ## Normal\n",
    "    #arr=(arr-np.mean(arr))/np.std(arr)\n",
    "    \n",
    "    ## Min-Max\n",
    "    # min_val=arr.min()\n",
    "    # max_val=arr.max()\n",
    "    # arr=arr/(min_val-max_val)\n",
    "\n",
    "    ## Image Scale\n",
    "    min_pixel = arr.min() \n",
    "    max_pixel = arr.max()\n",
    "    new_min = 0\n",
    "    new_max = 255\n",
    "    arr = (arr-min_pixel)*(255)/(max_pixel-min_pixel)+new_min \n",
    "    return arr\n",
    "  \n",
    "\n",
    "def preprocess_image_reduced(data,xco2=False):\n",
    "  \"\"\"\n",
    "  dimension reduced the output should be  (180,360,5)\n",
    "  \"\"\"\n",
    "  if xco2:\n",
    "    return data\n",
    "  return scale_image(convert_nan(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340.84854 407.2084\n",
      "\n",
      "xco2 shape: \n",
      "(421, 180, 360) (421, 180, 360)\n"
     ]
    }
   ],
   "source": [
    "#xco2 values are a constant value across the globe, so creating an image layer with constant value for the model\n",
    "xco2_images=[]\n",
    "min_xco2=np.min(xco2.XCO2.data)\n",
    "max_xco2=np.max(xco2.XCO2.data)\n",
    "new_min=0\n",
    "new_max=255\n",
    "print(min_xco2, max_xco2)\n",
    "print()\n",
    "\n",
    "\n",
    "for i in xco2.XCO2.data:\n",
    "    num = (i-min_xco2)*(new_max-new_min)/(max_xco2-min_xco2)+new_min\n",
    "    tmp = (np.repeat(num,180*360)).reshape(180,-1)\n",
    "    xco2_images.append(tmp)\n",
    "\n",
    "xco2_images=np.array(xco2_images)\n",
    "\n",
    "print(\"xco2 shape: \")\n",
    "print(xco2_images.shape, chl.Chl.data.shape)\n",
    "\n",
    "\n",
    "\n",
    "chl_images=preprocess_image_reduced(chl.Chl.data)\n",
    "mld_images=preprocess_image_reduced(mld.MLD.data)\n",
    "sss_images=preprocess_image_reduced(sss.SSS.data)\n",
    "sst_images=preprocess_image_reduced(sst.SST.data)\n",
    "xco2_images=preprocess_image_reduced(xco2_images,xco2=True)\n",
    "pco2_images=preprocess_image_reduced(pco2.pCO2.data)\n",
    "\n",
    "X = np.stack((chl_images, mld_images, sss_images, sst_images,xco2_images), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 180, 360, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X.reshape((421,180,360,5))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE=X[0].shape\n",
    "OUTPUT_SHAPE=pco2_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 180, 360, 64)      8064      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 180, 360, 64)      102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 60, 120, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 120, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 60, 120, 128)      204928    \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 60, 120, 128)      409728    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 180, 360, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 180, 360, 64)      204864    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 180, 360, 2)       3202      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 180, 360, 1)       3         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 180, 360)          0         \n",
      "=================================================================\n",
      "Total params: 933,253\n",
      "Trainable params: 933,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=5,activation='relu', padding=\"SAME\")\n",
    "\n",
    "\n",
    "base_model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, input_shape=INPUT_SHAPE),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.MaxPooling2D(pool_size=3),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "\n",
    "    keras.layers.UpSampling2D(size=3),\n",
    "    DefaultConv2D(filters=64),    \n",
    "    DefaultConv2D(filters=2),\n",
    "    DefaultConv2D(filters=1,kernel_size=1),\n",
    "    keras.layers.Reshape(OUTPUT_SHAPE)\n",
    "   \n",
    "])\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(loss=\"mean_squared_error\", optimizer=\"nadam\", metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 15s 558ms/step - loss: 1988068.3558 - mean_squared_error: 1988068.6517 - val_loss: 4246.2490 - val_mean_squared_error: 4246.2490\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 4320.3524 - mean_squared_error: 4320.3524 - val_loss: 4548.3579 - val_mean_squared_error: 4548.3584\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 3812.2001 - mean_squared_error: 3812.2002 - val_loss: 4216.2769 - val_mean_squared_error: 4216.2769\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 3703.0420 - mean_squared_error: 3703.0423 - val_loss: 4138.6978 - val_mean_squared_error: 4138.6978\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 5s 389ms/step - loss: 3787.9596 - mean_squared_error: 3787.9596 - val_loss: 3763.2827 - val_mean_squared_error: 3763.2827\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 5s 388ms/step - loss: 3641.6108 - mean_squared_error: 3641.6108 - val_loss: 3461.9358 - val_mean_squared_error: 3461.9358\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 5s 386ms/step - loss: 3772.7171 - mean_squared_error: 3772.7172 - val_loss: 3542.4075 - val_mean_squared_error: 3542.4072\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 5s 388ms/step - loss: 3471.8623 - mean_squared_error: 3471.8621 - val_loss: 3779.8293 - val_mean_squared_error: 3779.8291\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 5s 386ms/step - loss: 3393.6504 - mean_squared_error: 3393.6505 - val_loss: 3537.5522 - val_mean_squared_error: 3537.5522\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 3268.2145 - mean_squared_error: 3268.2144 - val_loss: 3451.3752 - val_mean_squared_error: 3451.3750\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 2988.8208 - mean_squared_error: 2988.8207 - val_loss: 4955.9414 - val_mean_squared_error: 4955.9414\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 3666.3777 - mean_squared_error: 3666.3777 - val_loss: 3419.1086 - val_mean_squared_error: 3419.1084\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 3175.6532 - mean_squared_error: 3175.6535 - val_loss: 3341.9397 - val_mean_squared_error: 3341.9399\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 5s 388ms/step - loss: 3284.9809 - mean_squared_error: 3284.9808 - val_loss: 3231.0366 - val_mean_squared_error: 3231.0366\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 5s 388ms/step - loss: 3012.7465 - mean_squared_error: 3012.7464 - val_loss: 3078.7183 - val_mean_squared_error: 3078.7185\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 5s 389ms/step - loss: 2646.7488 - mean_squared_error: 2646.7488 - val_loss: 2124.3494 - val_mean_squared_error: 2124.3491\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 2526.4036 - mean_squared_error: 2526.4037 - val_loss: 2584.9219 - val_mean_squared_error: 2584.9221\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 5s 388ms/step - loss: 2081.9702 - mean_squared_error: 2081.9702 - val_loss: 2018.9885 - val_mean_squared_error: 2018.9886\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 5s 388ms/step - loss: 1834.3310 - mean_squared_error: 1834.3309 - val_loss: 2504.8560 - val_mean_squared_error: 2504.8557\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 5s 388ms/step - loss: 1815.2755 - mean_squared_error: 1815.2755 - val_loss: 2188.8013 - val_mean_squared_error: 2188.8015\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 1747.8910 - mean_squared_error: 1747.8910 - val_loss: 2241.6711 - val_mean_squared_error: 2241.6711\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 5s 386ms/step - loss: 1682.6475 - mean_squared_error: 1682.6475 - val_loss: 2403.7434 - val_mean_squared_error: 2403.7434\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 1657.9432 - mean_squared_error: 1657.9433 - val_loss: 1699.5942 - val_mean_squared_error: 1699.5942\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 5s 388ms/step - loss: 1546.2408 - mean_squared_error: 1546.2408 - val_loss: 1861.9573 - val_mean_squared_error: 1861.9573\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 1539.0409 - mean_squared_error: 1539.0410 - val_loss: 1611.6501 - val_mean_squared_error: 1611.6499\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 5s 388ms/step - loss: 1399.0632 - mean_squared_error: 1399.0632 - val_loss: 2099.2935 - val_mean_squared_error: 2099.2932\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 5s 388ms/step - loss: 1439.2590 - mean_squared_error: 1439.2591 - val_loss: 1838.7961 - val_mean_squared_error: 1838.7961\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 1369.6401 - mean_squared_error: 1369.6401 - val_loss: 2053.3794 - val_mean_squared_error: 2053.3796\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 5s 388ms/step - loss: 1364.5455 - mean_squared_error: 1364.5455 - val_loss: 1627.4380 - val_mean_squared_error: 1627.4377\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 1279.5550 - mean_squared_error: 1279.5550 - val_loss: 1738.9126 - val_mean_squared_error: 1738.9126\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_path=\"../models/base_model/base_model_new.h5\"\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "history = base_model.fit(X,pco2_images, epochs=100, validation_data=(X,pco2_images),workers=-1,batch_size=32,callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image=base_model.predict(X[419:421],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(np.squeeze(predicted_image[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference=np.squeeze(pco2_images[419:421][1])-np.squeeze(predicted_image[0])\n",
    "plot_image(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(np.squeeze(pco2_images[419:421][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, input_shape=INPUT_SHAPE),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    DefaultConv2D(filters=256),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    keras.layers.UpSampling2D(size=2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "\n",
    "    keras.layers.UpSampling2D(size=2),\n",
    "    DefaultConv2D(filters=64),\n",
    "    DefaultConv2D(filters=64),\n",
    "    \n",
    "    DefaultConv2D(filters=2),\n",
    "    DefaultConv2D(filters=2),\n",
    "    DefaultConv2D(filters=1,kernel_size=1),\n",
    "    keras.layers.Reshape(OUTPUT_SHAPE)\n",
    "   \n",
    "])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss=\"mean_squared_error\", optimizer=\"nadam\", metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
