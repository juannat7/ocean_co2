{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifications\n",
    "1. Reduced Input Dimension\n",
    "2. Different handling of xco2: merge the value in as an additional input in the fully connected layer (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv/lib/python3.8/site-packages/xarray/backends/cfgrib_.py:27: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "!module load cuda11.0/toolkit cuda11.0/blas cudnn8.0-cuda11.0\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "tf.config.list_physical_devices()\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from utils import df_to_xarray,read_xarray,plot_image,preprocess_image_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "dir_name=\"../data/member_001\"\n",
    "chl,mld,sss,sst,u10,fg_co2,xco2,icefrac,patm,pco2=read_xarray(dir_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl_images=preprocess_image_reduced(chl.Chl.data)\n",
    "mld_images=preprocess_image_reduced(mld.MLD.data)\n",
    "sss_images=preprocess_image_reduced(sss.SSS.data)\n",
    "sst_images=preprocess_image_reduced(sst.SST.data)\n",
    "xco2_images=preprocess_image_reduced(xco2_images)\n",
    "pco2_images=preprocess_image_reduced(pco2.pCO2.data,True)\n",
    "\n",
    "X = np.stack((chl_images, mld_images, sss_images, sst_images,xco2_images), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.reshape((421,180,360,5))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE=X[0].shape\n",
    "OUTPUT_SHAPE=pco2_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=4,activation='relu', padding=\"SAME\")\n",
    "\n",
    "\n",
    "base_model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, input_shape=INPUT_SHAPE),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    keras.layers.UpSampling2D(size=2),\n",
    "    DefaultConv2D(filters=64),\n",
    "    DefaultConv2D(filters=64),\n",
    "    \n",
    "    DefaultConv2D(filters=2),\n",
    "    DefaultConv2D(filters=2),\n",
    "    DefaultConv2D(filters=1,kernel_size=1,activation='sigmoid'),\n",
    "    keras.layers.Reshape(OUTPUT_SHAPE)\n",
    "   \n",
    "])\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(loss=\"mean_squared_error\", optimizer=\"nadam\", metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"../models/base_model/base_model.h5\"\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "history = base_model.fit(X,pco2_images, epochs=100, validation_data=(X,pco2_images),workers=-1,batch_size=32,callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
