{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifications\n",
    "\n",
    "Link to Interactive Notebook: \n",
    "https://colab.research.google.com/drive/1sbJTsgCsAQwCkGdLXK7EdgkaTpiTGBM1#scrollTo=T71qxHyh9p23\n",
    "\n",
    "1. Reduced Input Dimension\n",
    "2. Different handling of xco2: merge the value in as an additional input in the fully connected layer (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#!module load cuda11.0/toolkit cuda11.0/blas cudnn8.0-cuda11.0\n",
    "\n",
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "#tf.config.list_physical_devices()\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from utils import df_to_xarray,read_xarray,plot_image,preprocess_image_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "dir_name=\"../data/data1\"\n",
    "val_dir_name=\"../data/data2\"\n",
    "\n",
    "\n",
    "chl,mld,sss,sst,u10,fg_co2,xco2,icefrac,patm,pco2=read_xarray(dir_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nan(arr):\n",
    "    nans=np.isnan(arr)\n",
    "    min_val=arr[~nans].min()\n",
    "    #print(min_val)\n",
    "    arr[nans]=min_val-1\n",
    "    return arr\n",
    "\n",
    "def add_dimension(arr):\n",
    "    images=np.expand_dims(arr, axis=3)\n",
    "    return images\n",
    "\n",
    "def scale_image(arr):\n",
    "    ## Normal\n",
    "    #arr=(arr-np.mean(arr))/np.std(arr)\n",
    "    \n",
    "    ## Min-Max\n",
    "    # min_val=arr.min()\n",
    "    # max_val=arr.max()\n",
    "    # arr=arr/(min_val-max_val)\n",
    "\n",
    "    ## Image Scale\n",
    "    min_pixel = arr.min() \n",
    "    max_pixel = arr.max()\n",
    "    new_min = 0\n",
    "    new_max = 255\n",
    "    arr = (arr-min_pixel)*(255)/(max_pixel-min_pixel)+new_min \n",
    "    return arr\n",
    "  \n",
    "def preprocess_image(data,train=False):\n",
    "    if train:\n",
    "      return add_dimension(convert_nan(data))\n",
    "    else:\n",
    "      return add_dimension(scale_image(convert_nan(data))/255.0)\n",
    "\n",
    "def preprocess_image_reduced(data,xco2=False):\n",
    "  \"\"\"\n",
    "  dimension reduced the output should be  (180,360,5)\n",
    "  \"\"\"\n",
    "  if xco2:\n",
    "    return data\n",
    "  return scale_image(convert_nan(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl_images=preprocess_image_reduced(chl.Chl.data)\n",
    "mld_images=preprocess_image_reduced(mld.MLD.data)\n",
    "sss_images=preprocess_image_reduced(sss.SSS.data)\n",
    "sst_images=preprocess_image_reduced(sst.SST.data)\n",
    "xco2_images=preprocess_image_reduced(xco2.XCO2.data,xco2=True)\n",
    "pco2_images=preprocess_image_reduced(pco2.pCO2.data,pco2=True)\n",
    "\n",
    "X = np.stack((chl_images, mld_images, sss_images, sst_images,xco2_images), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 180, 360, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X.reshape((421,180,360,5))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE=X[0].shape\n",
    "OUTPUT_SHAPE=pco2_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=4,activation='relu', padding=\"SAME\")\n",
    "\n",
    "base_model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, input_shape=INPUT_SHAPE),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.MaxPooling2D(pool_size=3),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "\n",
    "    keras.layers.UpSampling2D(size=3),\n",
    "    DefaultConv2D(filters=64),    \n",
    "    DefaultConv2D(filters=2),\n",
    "    DefaultConv2D(filters=1,kernel_size=1),\n",
    "    keras.layers.Reshape(OUTPUT_SHAPE)\n",
    "   \n",
    "])\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(loss=\"mean_squared_error\", optimizer=\"nadam\", metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"../models/base_model/base_model.h5\"\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "history = base_model.fit(X,pco2_images, epochs=100, validation_data=(X,pco2_images),workers=-1,batch_size=32,callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image=base_model.predict(X[419:421],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(np.squeeze(predicted_image[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference=np.squeeze(pco2_images[419:421][1])-np.squeeze(predicted_image[0])\n",
    "plot_image(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(np.squeeze(pco2_images[419:421][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
