{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Base\n",
    "\n",
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/xarray/backends/cfgrib_.py:27: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n",
      "2022-10-19 14:51:01.610223: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64\n",
      "2022-10-19 14:51:01.610600: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "#import hvplot.xarray\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sys.path.insert(0, '../../src')\n",
    "\n",
    "from utils import df_to_xarray,read_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/xarray/backends/plugins.py:61: RuntimeWarning: Engine 'cfgrib' loading failed:\n",
      "ecCodes library not found using ['eccodes', 'libeccodes.so', 'libeccodes']\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Reading Data\n",
    "dir_name=\"../../data/member_001\"\n",
    "\n",
    "chl,mld,sss,sst,u10,xco2,icefrac,patm,pco2=read_xarray(dir_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one singular df\n",
    "data_read=xr.merge([mld.MLD,mld.MLD_socat,sst.SST,sst.SST_socat,sss.SSS,sss.SSS_socat,xco2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data=data_read.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data=tmp_data.drop(columns=['bnds','TLONG', 'TLAT', 'time_bnds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl_data=chl.Chl.to_dataframe().reset_index()\n",
    "chl_data_socat=chl.Chl_socat.to_dataframe().reset_index()\n",
    "pco2_data=pco2.pCO2.to_dataframe().reset_index()\n",
    "pco2_data_socat=pco2.pCO2_socat.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data[\"Chl_socat\"]=chl_data_socat[\"Chl_socat\"]\n",
    "tmp_data[\"Chl\"]=chl_data[\"Chl\"]\n",
    "tmp_data[\"pCO2_socat\"]=pco2_data_socat[\"pCO2_socat\"]\n",
    "tmp_data[\"pCO2\"]=pco2_data[\"pCO2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xlon                 0\n",
       "ylat                 0\n",
       "time                 0\n",
       "MLD           19980660\n",
       "MLD_socat     19980660\n",
       "SST           19980660\n",
       "SST_socat     19980660\n",
       "SSS           19980660\n",
       "SSS_socat     19980660\n",
       "XCO2                 0\n",
       "Chl_socat     37271130\n",
       "Chl           37271130\n",
       "pCO2_socat    37271130\n",
       "pCO2          37271130\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_socat = ['time','xlon', 'ylat','MLD_socat', 'SST_socat', 'SSS_socat','Chl_socat', 'XCO2','pCO2_socat']\n",
    "features = ['time','xlon', 'ylat','MLD','SST','SSS','Chl','XCO2','pCO2']\n",
    "\n",
    "# create separate dataframe for socat\n",
    "combined_socat=tmp_data[features_socat]\n",
    "combined=tmp_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# drop rows where pco2 or pco2_socat == NA or 0\n",
    "combined_socat.dropna(subset = [\"pCO2_socat\"], inplace=True)\n",
    "combined_socat= combined_socat[combined_socat['pCO2_socat']!=0]\n",
    "\n",
    "combined.dropna(subset = [\"pCO2\"], inplace=True)\n",
    "combined= combined[combined['pCO2']!=0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_socat= combined_socat[combined_socat['MLD_socat']!=0]\n",
    "combined_socat=combined_socat.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating X and y\n",
    "X_socat=combined_socat.iloc[:,3:-1]\n",
    "X=combined.iloc[:,3:-1]\n",
    "y=combined.loc[:,'pCO2']\n",
    "y_socat=combined_socat.loc[:,'pCO2_socat']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation\n",
    "We can save 6452246 rows through imputation.\n",
    "\n",
    "Try Building a Custom Imputation based on lon and lat?\n",
    "https://towardsdatascience.com/coding-a-custom-imputer-in-scikit-learn-31bd68e541de\n",
    "\n",
    "\n",
    "Also, consider using Hurdle Model?\n",
    "\n",
    "https://geoffruddock.com/building-a-hurdle-regression-estimator-in-scikit-learn/\n",
    "\n",
    "#### Two Different Imputation Methods\n",
    "- KNNImputer: fill in the average of the 2 nearest neighbors, takes a long time to train\n",
    "- Simple Imputer: just fill in using the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLD_socat</th>\n",
       "      <th>SST_socat</th>\n",
       "      <th>SSS_socat</th>\n",
       "      <th>Chl_socat</th>\n",
       "      <th>XCO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2621.000000</td>\n",
       "      <td>2621.000000</td>\n",
       "      <td>2621.000000</td>\n",
       "      <td>2621.000000</td>\n",
       "      <td>2621.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.917508</td>\n",
       "      <td>15.487437</td>\n",
       "      <td>33.457011</td>\n",
       "      <td>0.225942</td>\n",
       "      <td>387.387939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>50.263286</td>\n",
       "      <td>9.490092</td>\n",
       "      <td>1.526085</td>\n",
       "      <td>0.515163</td>\n",
       "      <td>12.510401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.868806</td>\n",
       "      <td>-1.825340</td>\n",
       "      <td>26.063950</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>343.963409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.666689</td>\n",
       "      <td>8.050923</td>\n",
       "      <td>32.406136</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>378.810028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.688725</td>\n",
       "      <td>15.920362</td>\n",
       "      <td>33.653847</td>\n",
       "      <td>0.135566</td>\n",
       "      <td>389.602814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>69.267616</td>\n",
       "      <td>24.034296</td>\n",
       "      <td>34.578911</td>\n",
       "      <td>0.190518</td>\n",
       "      <td>397.187469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1193.783569</td>\n",
       "      <td>30.828823</td>\n",
       "      <td>36.894070</td>\n",
       "      <td>6.348923</td>\n",
       "      <td>406.971283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MLD_socat    SST_socat    SSS_socat    Chl_socat         XCO2\n",
       "count  2621.000000  2621.000000  2621.000000  2621.000000  2621.000000\n",
       "mean     51.917508    15.487437    33.457011     0.225942   387.387939\n",
       "std      50.263286     9.490092     1.526085     0.515163    12.510401\n",
       "min       7.868806    -1.825340    26.063950     0.001966   343.963409\n",
       "25%      23.666689     8.050923    32.406136     0.104000   378.810028\n",
       "50%      39.688725    15.920362    33.653847     0.135566   389.602814\n",
       "75%      69.267616    24.034296    34.578911     0.190518   397.187469\n",
       "max    1193.783569    30.828823    36.894070     6.348923   406.971283"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_socat.describe()\n",
    "#get rid of 0s by converting it to NANs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLD</th>\n",
       "      <th>SST</th>\n",
       "      <th>SSS</th>\n",
       "      <th>Chl</th>\n",
       "      <th>XCO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.083822e+07</td>\n",
       "      <td>1.083822e+07</td>\n",
       "      <td>1.083822e+07</td>\n",
       "      <td>1.729047e+07</td>\n",
       "      <td>1.729047e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.533868e+01</td>\n",
       "      <td>1.319081e+01</td>\n",
       "      <td>3.375592e+01</td>\n",
       "      <td>3.449500e-01</td>\n",
       "      <td>3.701860e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.373071e+01</td>\n",
       "      <td>1.153312e+01</td>\n",
       "      <td>1.569614e+00</td>\n",
       "      <td>8.521562e-01</td>\n",
       "      <td>1.869547e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.500032e+00</td>\n",
       "      <td>-1.936021e+00</td>\n",
       "      <td>1.376396e+01</td>\n",
       "      <td>-4.092084e-01</td>\n",
       "      <td>3.408485e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.466645e+01</td>\n",
       "      <td>6.017284e-01</td>\n",
       "      <td>3.324879e+01</td>\n",
       "      <td>1.087646e-01</td>\n",
       "      <td>3.547707e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.551451e+01</td>\n",
       "      <td>1.352542e+01</td>\n",
       "      <td>3.385484e+01</td>\n",
       "      <td>1.580932e-01</td>\n",
       "      <td>3.681608e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.369460e+01</td>\n",
       "      <td>2.482988e+01</td>\n",
       "      <td>3.459950e+01</td>\n",
       "      <td>2.111136e-01</td>\n",
       "      <td>3.854302e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.868325e+03</td>\n",
       "      <td>3.407636e+01</td>\n",
       "      <td>4.305632e+01</td>\n",
       "      <td>1.467028e+01</td>\n",
       "      <td>4.072084e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MLD           SST           SSS           Chl          XCO2\n",
       "count  1.083822e+07  1.083822e+07  1.083822e+07  1.729047e+07  1.729047e+07\n",
       "mean   6.533868e+01  1.319081e+01  3.375592e+01  3.449500e-01  3.701860e+02\n",
       "std    5.373071e+01  1.153312e+01  1.569614e+00  8.521562e-01  1.869547e+01\n",
       "min    7.500032e+00 -1.936021e+00  1.376396e+01 -4.092084e-01  3.408485e+02\n",
       "25%    3.466645e+01  6.017284e-01  3.324879e+01  1.087646e-01  3.547707e+02\n",
       "50%    5.551451e+01  1.352542e+01  3.385484e+01  1.580932e-01  3.681608e+02\n",
       "75%    8.369460e+01  2.482988e+01  3.459950e+01  2.111136e-01  3.854302e+02\n",
       "max    1.868325e+03  3.407636e+01  4.305632e+01  1.467028e+01  4.072084e+02"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time          0\n",
       "xlon          0\n",
       "ylat          0\n",
       "MLD_socat     0\n",
       "SST_socat     0\n",
       "SSS_socat     0\n",
       "Chl_socat     0\n",
       "XCO2          0\n",
       "pCO2_socat    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can save this many rows through imputation.\n",
    "# These rows have xCO2, pXO2 and CHL, but no MLD, SSS, SST\n",
    "combined_socat.isna().sum()\n",
    "\n",
    "# get rid of NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two Different Imputation Methods\n",
    "\n",
    "# KNNImputer\n",
    "# from sklearn.impute import KNNImputer\n",
    "# imp = KNNImputer(n_neighbors=2)\n",
    "# X=imp.fit_transform(X)\n",
    "# X_socat=imp.fit_transform(X_socat)\n",
    "\n",
    "# SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X=imp.fit_transform(X)\n",
    "X_socat=imp.fit_transform(X_socat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling - Random Forest: full\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 20building tree 2 of 20\n",
      "\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_socat, y_socat, test_size=0.3, random_state= 73)\n",
    "\n",
    "regressor=RandomForestRegressor(n_estimators=20, random_state=42, verbose=3,n_jobs=-1, \n",
    "                                max_depth=10,warm_start= True)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [31.94232548 30.06048346 35.2441136 ]\n",
      "Mean: 32.41564084711841\n",
      "Standard deviation: 2.1425103568649506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    3.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "forest_scores = cross_val_score(regressor, X_train, y_train,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=3)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Result: full\n",
    "\n",
    "Socat RMSE: \n",
    "\n",
    "Whole Grid Rmse: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.37670213910077"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On Socat\n",
    "y_pred=regressor.predict(X_test)\n",
    "test_mse=mean_squared_error(y_test, y_pred,squared=True)\n",
    "np.sqrt(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46.605525140120086"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 20\n",
      "building tree 14 of 20\n",
      "building tree 18 of 20\n",
      "building tree 2 of 20\n",
      "building tree 7 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 17 of 20\n",
      "building tree 20 of 20\n",
      "building tree 4 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 18 of 20\n",
      "building tree 2 of 20\n",
      "building tree 5 of 20\n",
      "building tree 8 of 20\n",
      "building tree 10 of 20\n",
      "building tree 13 of 20\n",
      "building tree 17 of 20\n",
      "building tree 20 of 20\n",
      "building tree 4 of 20\n",
      "building tree 8 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 19 of 20\n",
      "building tree 2 of 20\n",
      "building tree 7 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 19 of 20\n",
      "building tree 1 of 20\n",
      "building tree 7 of 20\n",
      "building tree 12 of 20\n",
      "building tree 16 of 20\n",
      "building tree 19 of 20\n",
      "building tree 3 of 20\n",
      "building tree 6 of 20\n",
      "building tree 18 of 20\n",
      "building tree 3 of 20\n",
      "building tree 6 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 17 of 20\n",
      "building tree 20 of 20\n",
      "building tree 4 of 20\n",
      "building tree 6 of 20\n",
      "building tree 9 of 20\n",
      "building tree 11 of 20\n",
      "building tree 15 of 20\n",
      "building tree 1 of 20\n",
      "building tree 5 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 1 of 20\n",
      "building tree 5 of 20\n",
      "building tree 8 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n"
     ]
    }
   ],
   "source": [
    "## The whole grid\n",
    "y_pred=regressor.predict(X)\n",
    "final_test_rmse=np.sqrt(mean_squared_error(y, y_pred,squared=True))\n",
    "error=y-y_pred\n",
    "\n",
    "final_test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling - Random Forest: Socat\n",
    "\n",
    "\n",
    "Uses train_test_split build into sklearn.model_selection\n",
    "\n",
    "\n",
    "By default this method shuffles the data (30% = testing 70%=training/validation)\n",
    "- Will test validation via 7-fold cross validation\n",
    "\n",
    "Train  = 70%, Test   = 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_socat, y_socat, test_size=0.3, random_state= 73)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=20, random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor=RandomForestRegressor(n_estimators=20, random_state=42)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "forest_scores = cross_val_score(regressor, X_train, y_train,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=7)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [28.43812975 28.80551361 31.5301553  28.27728449 27.59931712 33.37769013\n",
      " 35.27325214]\n",
      "Mean: 30.471620363351235\n",
      "Standard deviation: 2.7411581761782626\n"
     ]
    }
   ],
   "source": [
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=7, estimator=RandomForestRegressor(random_state=42),\n",
       "                   param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x15544f8ae6d0>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x15554e8e0a00>},\n",
       "                   random_state=42, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fine Tuning Using RandomizedSearch\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=20, high=50),\n",
    "        'max_features': randint(low=1, high=6),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=7, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(X_train, y_train)\n",
    "\n",
    "final_model =rnd_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model =rnd_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Result\n",
    "\n",
    "Test Set RMSE: 23.818525580843453\n",
    "\n",
    "Whole Grid Rmse: 40.38668015093895"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.668254832945372"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=final_model.predict(X_test)\n",
    "test_mse=mean_squared_error(y_test, y_pred,squared=True)\n",
    "np.sqrt(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The whole grid\n",
    "y_pred=final_model.predict(X)\n",
    "final_test_rmse=np.sqrt(mean_squared_error(y, y_pred,squared=True))\n",
    "error=y-y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.38668015093895"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"residual\"] = np.abs(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data=combined[[\"time\",\"xlon\",\"ylat\",\"residual\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=result_data.columns.tolist()\n",
    "cols=[cols[0],cols[2],cols[1],cols[3]]\n",
    "result_data=result_data[cols]\n",
    "result_data.columns=['time','lat','lon','residual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cftime.DatetimeNoLeap(1994, 2, 1, 0, 0, 0, 0, has_year_zero=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data['time'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>1994-02-01 00:00:00</td>\n",
       "      <td>-84.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>181.379256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>1994-03-01 00:00:00</td>\n",
       "      <td>-84.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>184.723367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>1994-03-01 00:00:00</td>\n",
       "      <td>-84.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>186.377531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>1994-04-01 00:00:00</td>\n",
       "      <td>-84.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>187.531068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>1994-04-01 00:00:00</td>\n",
       "      <td>-84.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>189.540438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27280795</th>\n",
       "      <td>2016-12-01 00:00:00</td>\n",
       "      <td>89.5</td>\n",
       "      <td>179.5</td>\n",
       "      <td>17.859512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27280796</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>89.5</td>\n",
       "      <td>179.5</td>\n",
       "      <td>20.821743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27280797</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>89.5</td>\n",
       "      <td>179.5</td>\n",
       "      <td>20.794660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27280798</th>\n",
       "      <td>2017-02-01 00:00:00</td>\n",
       "      <td>89.5</td>\n",
       "      <td>179.5</td>\n",
       "      <td>20.838025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27280799</th>\n",
       "      <td>2017-02-01 00:00:00</td>\n",
       "      <td>89.5</td>\n",
       "      <td>179.5</td>\n",
       "      <td>20.811306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17290470 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time   lat    lon    residual\n",
       "4499      1994-02-01 00:00:00 -84.5    0.5  181.379256\n",
       "4500      1994-03-01 00:00:00 -84.5    0.5  184.723367\n",
       "4501      1994-03-01 00:00:00 -84.5    0.5  186.377531\n",
       "4502      1994-04-01 00:00:00 -84.5    0.5  187.531068\n",
       "4503      1994-04-01 00:00:00 -84.5    0.5  189.540438\n",
       "...                       ...   ...    ...         ...\n",
       "27280795  2016-12-01 00:00:00  89.5  179.5   17.859512\n",
       "27280796  2017-01-01 00:00:00  89.5  179.5   20.821743\n",
       "27280797  2017-01-01 00:00:00  89.5  179.5   20.794660\n",
       "27280798  2017-02-01 00:00:00  89.5  179.5   20.838025\n",
       "27280799  2017-02-01 00:00:00  89.5  179.5   20.811306\n",
       "\n",
       "[17290470 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert a DataFrame with a non-unique MultiIndex into xarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     ds \u001b[38;5;241m=\u001b[39m df_out\u001b[38;5;241m.\u001b[39mto_xarray()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n\u001b[0;32m---> 18\u001b[0m ds\u001b[38;5;241m=\u001b[39m\u001b[43mtmp_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36mtmp_df\u001b[0;34m(df_in)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# convert to xarray dataset\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# old way to `dimt, = ds_skeleton.time.shape` ect. to get dimensions\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# then reshape  `df_out.values.reshape(dim_lat, dim_lon, dim_time)`\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# finally create a custom dataset\u001b[39;00m\n\u001b[1;32m     14\u001b[0m df_out\u001b[38;5;241m.\u001b[39mset_index([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mdf_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_xarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/pandas/core/generic.py:3109\u001b[0m, in \u001b[0;36mNDFrame.to_xarray\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xarray\u001b[38;5;241m.\u001b[39mDataArray\u001b[38;5;241m.\u001b[39mfrom_series(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   3108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/xarray/core/dataset.py:5465\u001b[0m, in \u001b[0;36mDataset.from_dataframe\u001b[0;34m(cls, dataframe, sparse)\u001b[0m\n\u001b[1;32m   5462\u001b[0m idx \u001b[38;5;241m=\u001b[39m remove_unused_levels_categories(dataframe\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, pd\u001b[38;5;241m.\u001b[39mMultiIndex) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m-> 5465\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   5466\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot convert a DataFrame with a non-unique MultiIndex into xarray\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5467\u001b[0m     )\n\u001b[1;32m   5469\u001b[0m \u001b[38;5;66;03m# Cast to a NumPy array first, in case the Series is a pandas Extension\u001b[39;00m\n\u001b[1;32m   5470\u001b[0m \u001b[38;5;66;03m# array (which doesn't have a valid NumPy dtype)\u001b[39;00m\n\u001b[1;32m   5471\u001b[0m \u001b[38;5;66;03m# TODO: allow users to control how this casting happens, e.g., by\u001b[39;00m\n\u001b[1;32m   5472\u001b[0m \u001b[38;5;66;03m# forwarding arguments to pandas.Series.to_numpy?\u001b[39;00m\n\u001b[1;32m   5473\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [(k, np\u001b[38;5;241m.\u001b[39masarray(v)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m dataframe\u001b[38;5;241m.\u001b[39mitems()]\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert a DataFrame with a non-unique MultiIndex into xarray"
     ]
    }
   ],
   "source": [
    "def tmp_df(df_in=None):\n",
    "    dates = xr.cftime_range(start=f'1982-02-01', end=f'2018-12-01',freq='MS') \n",
    "    ds_skeleton = xr.Dataset({'lon':np.arange(0.5, 360, 1), \n",
    "                              'lat':np.arange(-89.5, 90, 1),\n",
    "                              'time':dates})    \n",
    "    # make dataframe\n",
    "    skeleton = df_in.reset_index()[['lon','lat','time']]\n",
    "    # Merge predictions with df_all dataframe\n",
    "    df_out = skeleton.merge(df_in, how = 'left', on = ['lon','lat','time'])\n",
    "    # convert to xarray dataset\n",
    "    # old way to `dimt, = ds_skeleton.time.shape` ect. to get dimensions\n",
    "    # then reshape  `df_out.values.reshape(dim_lat, dim_lon, dim_time)`\n",
    "    # finally create a custom dataset\n",
    "    df_out.set_index(['lon','lat','time'], inplace=True)\n",
    "    ds = df_out.to_xarray()\n",
    "    return ds\n",
    "\n",
    "ds=tmp_df(result_data)\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 20\n",
      "building tree 6 of 20\n",
      "building tree 10 of 20\n",
      "building tree 13 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 4 of 20\n",
      "building tree 7 of 20\n",
      "building tree 11 of 20\n",
      "building tree 15 of 20\n",
      "building tree 19 of 20\n",
      "building tree 3 of 20\n",
      "building tree 8 of 20\n",
      "building tree 14 of 20\n",
      "building tree 4 of 20\n",
      "building tree 7 of 20\n",
      "building tree 12 of 20\n",
      "building tree 15 of 20\n",
      "building tree 20 of 20\n",
      "building tree 2 of 20\n",
      "building tree 6 of 20\n",
      "building tree 10 of 20\n",
      "building tree 14 of 20\n",
      "building tree 18 of 20\n",
      "building tree 2 of 20\n",
      "building tree 7 of 20\n",
      "building tree 11 of 20\n",
      "building tree 15 of 20\n",
      "building tree 18 of 20\n",
      "building tree 3 of 20\n",
      "building tree 8 of 20\n",
      "building tree 11 of 20\n",
      "building tree 16 of 20\n",
      "building tree 1 of 20\n",
      "building tree 5 of 20\n",
      "building tree 9 of 20\n",
      "building tree 13 of 20\n",
      "building tree 17 of 20\n",
      "building tree 1 of 20\n",
      "building tree 5 of 20\n",
      "building tree 9 of 20\n",
      "building tree 12 of 20\n",
      "building tree 16 of 20\n",
      "building tree 19 of 20\n",
      "building tree 2 of 20\n",
      "building tree 5 of 20\n",
      "building tree 9 of 20\n",
      "building tree 14 of 20\n",
      "building tree 19 of 20\n",
      "building tree 3 of 20\n",
      "building tree 8 of 20\n",
      "building tree 12 of 20\n",
      "building tree 16 of 20\n",
      "building tree 20 of 20\n",
      "building tree 4 of 20\n",
      "building tree 6 of 20\n",
      "building tree 10 of 20\n",
      "building tree 13 of 20\n",
      "building tree 17 of 20\n",
      "building tree 20 of 20\n"
     ]
    }
   ],
   "source": [
    "a=ds.residual.hvplot(groupby=\"time\",width=512,height=512, widget_type='scrubber', widget_location='bottom')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
