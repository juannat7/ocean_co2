{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN_LSTM Base\n",
    "- to capture spatial (CNN) -temporal (LSTM) information\n",
    "- often used in NEXT FRAME VIDEO PREDICTION problem in vision\n",
    "\n",
    "### Colab Link\n",
    "- Run it with GPU: https://colab.research.google.com/drive/1mNi_gSTWDSto7EWnyh4ZVuQA3VfN56Hm#scrollTo=zVGtIJiqnJLB\n",
    "\n",
    "\n",
    "### Sources\n",
    "\n",
    "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9063513\n",
    "\n",
    "https://keras.io/examples/vision/conv_lstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import df_to_xarray,read_xarray,plot_image,preprocess_image,create_shifted_frames\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "#!module load cuda11.0/toolkit cuda11.0/blas cudnn8.0-cuda11.0\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "# Reading Data\n",
    "\n",
    "dir_name=\"../data/data1\"\n",
    "val_dir_name=\"../data/data2\"\n",
    "\n",
    "chl,mld,sss,sst,u10,fg_co2,xco2,icefrac,patm,pco2=read_xarray(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the Data\n",
    "chl_images=preprocess_image(chl.Chl.data)\n",
    "mld_images=preprocess_image(mld.MLD.data)\n",
    "sss_images=preprocess_image(sss.SSS.data)\n",
    "sst_images=preprocess_image(sst.SST.data)\n",
    "xco2_images=preprocess_image(xco2.XCO2.data,xco2=True)\n",
    "pco2_images=preprocess_image(pco2.pCO2.data,pco2=True)\n",
    "\n",
    "x_train, y_train = create_shifted_frames(train_data)\n",
    "\n",
    "print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = layers.Input(shape=(None, *x_train.shape[2:]))\n",
    "\n",
    "# We will construct 3 `ConvLSTM2D` layers with batch normalization,\n",
    "# followed by a `Conv3D` layer for the spatiotemporal outputs.\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(5, 5),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(inp)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(3, 3),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(1, 1),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(x)\n",
    "x = layers.Conv3D(\n",
    "    filters=1, kernel_size=(3, 3, 3), activation=\"relu\", padding=\"same\"\n",
    ")(x)\n",
    "\n",
    "# Next, we will build the complete model and compile it.\n",
    "model = keras.models.Model(inp, x)\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "INPUT_SHAPE=X[0].shape\n",
    "OUTPUT_SHAPE=pco2_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"../models/base_CNN_LSTM.h5\"\n",
    "\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "# Define modifiable training hyperparameters.\n",
    "epochs = 20\n",
    "batch_size = 4\n",
    "\n",
    "# Fit the model to the training data.\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_train, y_train),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
