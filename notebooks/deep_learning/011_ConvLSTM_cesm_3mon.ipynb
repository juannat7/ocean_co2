{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "012f80e3-065f-4481-8b61-0b16c778386f",
   "metadata": {},
   "source": [
    "## generate previous frames with pCO2 and fit it against ConvLSTM for multiple members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c497b4-9499-4832-aed7-d1c3b9d4b5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/xarray/backends/cfgrib_.py:27: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n",
      "2023-09-10 12:24:36.967359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '../../src')\n",
    "\n",
    "from utils import df_to_xarray,read_xarray, custom_rmse\n",
    "\n",
    "sys.path.insert(0, '../../src/preprocess')\n",
    "from data_preprocess import preprocess_image_reduced,preprocess_images_nfp, inverse_scale_frame\n",
    "from data_preprocess import preprocess_images, inverse_scale_image, preprocess_image_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "608f7ff1-e153-4853-bc4a-c4592c8f5906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsmodels: 0.13.5\n"
     ]
    }
   ],
   "source": [
    "import statsmodels\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "print('statsmodels: %s' % statsmodels.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ea67d-8bc2-422f-8c39-0de87dd0ed5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  CESM Previous Frame generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8115c973-ef73-46a6-b8b7-9142c659c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_map = pd.read_csv(\"../../src/dist_map.csv\",header=None).to_numpy()\n",
    "dist_map = np.roll(np.fliplr(dist_map),180)\n",
    "dist_map = np.repeat(dist_map[np.newaxis, :, : ], 421, axis=0)\n",
    "\n",
    "def custom_rmse2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    custom_rmse(y_true, y_pred)\n",
    "    calculates root square mean value with focusing only on the ocean\n",
    "    + difference between sss\n",
    "    \"\"\"\n",
    "    idx  = tf.not_equal(y_true, 0.0)\n",
    "    idx2  = tf.equal(y_true, 0.0)\n",
    "    \n",
    "    y_pred1 = tf.boolean_mask(y_pred,idx)\n",
    "    y_true1 = tf.boolean_mask(y_true,idx)\n",
    "    y_true1 = tf.cast(y_true1, y_pred.dtype)\n",
    "    \n",
    "    \n",
    "    return rmse1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31a572ea-5c8a-4062-ad05-0d655167249a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/xarray/backends/plugins.py:61: RuntimeWarning: Engine 'cfgrib' loading failed:\n",
      "ecCodes library not found using ['eccodes', 'libeccodes.so', 'libeccodes']\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Reading Data\n",
    "dir = \"../../data/\"\n",
    "dir_name = \"../../data/member_001\"\n",
    "data_nums = [\"001\", \"002\", \"009\", \"010\", \"011\", \"012\", \"013\", \"014\", \"015\", \"016\", \"017\", \"018\", \"020\",\n",
    "             \"021\", \"023\", \"024\", \"025\", \"030\", \"031\", \"034\", \"035\", \"101\", \"102\", \"103\", \"104\"]\n",
    "\n",
    "X_all = np.empty((0, 180, 360, 5))\n",
    "y_all = np.empty((0, 180, 360))\n",
    "\n",
    "for i in range(1):\n",
    "    dir_name = dir + \"member_\" + str(data_nums[i])\n",
    "    chl,mld,sss,sst,u10,xco2,icefrac,patm,pco2 = read_xarray(dir_name,num =data_nums[i])\n",
    "    \n",
    "    chl_images = preprocess_image_reduced(chl.Chl.data)\n",
    "    sss_images = preprocess_image_reduced(sss.SSS.data)\n",
    "    sst_images = preprocess_image_reduced(sst.SST.data)\n",
    "    mld_images = preprocess_image_reduced(mld.MLD.data)\n",
    "    xco2_images = preprocess_image_reduced(xco2.XCO2.data,xco2=True)\n",
    "    y1 = preprocess_image_reduced(pco2.pCO2.data)\n",
    "    dist_map = preprocess_image_reduced(dist_map)\n",
    "    X1 = np.dstack((chl_images, dist_map, sss_images, sst_images, xco2_images))\n",
    "    #X1 = np.dstack((chl_images, mld_images, sss_images, sst_images, xco2_images))\n",
    "    X1 = X1.reshape((421,180,360,5),order='F')\n",
    "    \n",
    "    X_all = np.concatenate((X_all, X1))\n",
    "    y_all = np.concatenate((y_all, y1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e231214a-a785-4872-8145-610401a04b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180, 360, 5), (421, 180, 360, 5), (421, 180, 360))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE=X_all[0].shape\n",
    "OUTPUT_SHAPE=y_all[0].shape\n",
    "\n",
    "INPUT_SHAPE, X_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adea77c5-9eca-4d23-adfc-860398ab961b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71dcf66-0fb2-475f-830f-4e0e44cec5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 12:24:46.255927: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-09-10 12:24:46.257102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-09-10 12:24:46.317374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Tesla V100S-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 1.03TiB/s\n",
      "2023-09-10 12:24:46.317429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-09-10 12:24:46.320812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-09-10 12:24:46.320896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-09-10 12:24:46.322473: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-09-10 12:24:46.323116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-09-10 12:24:46.326487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-09-10 12:24:46.327506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-09-10 12:24:46.327995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-09-10 12:24:46.328424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-09-10 12:24:46.328916: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-10 12:24:46.329113: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-09-10 12:24:46.329360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Tesla V100S-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 1.03TiB/s\n",
      "2023-09-10 12:24:46.329384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-09-10 12:24:46.329404: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-09-10 12:24:46.329415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-09-10 12:24:46.329427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-09-10 12:24:46.329437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-09-10 12:24:46.329448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-09-10 12:24:46.329459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-09-10 12:24:46.329470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-09-10 12:24:46.329761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-09-10 12:24:46.329787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-09-10 12:24:46.804202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-09-10 12:24:46.804226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-09-10 12:24:46.804232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-09-10 12:24:46.804873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30130 MB memory) -> physical GPU (device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=5,activation='elu',\n",
    "                        padding=\"SAME\")\n",
    "\n",
    "base_model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=32, input_shape=INPUT_SHAPE),\n",
    "    DefaultConv2D(filters=32),\n",
    "    keras.layers.MaxPooling2D(pool_size=3),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    DefaultConv2D(filters=64),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.MaxPooling2D(pool_size=3),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.UpSampling2D(size=3),\n",
    "    DefaultConv2D(filters=64),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.UpSampling2D(size=3),\n",
    "    DefaultConv2D(filters=32),\n",
    "    DefaultConv2D(filters=2),\n",
    "    DefaultConv2D(filters=1,kernel_size=1),\n",
    "    keras.layers.Reshape(OUTPUT_SHAPE)\n",
    "])\n",
    "\n",
    "myLearnRate=0.0005\n",
    "custom_opt = tf.keras.optimizers.Adam(learning_rate=myLearnRate)\n",
    "\n",
    "#rmse 13\n",
    "\n",
    "\n",
    "\n",
    "base_model.compile(loss=custom_rmse, optimizer=custom_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4ba4bec-c490-46fe-9724-efbf9f55cdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 12:24:53.390071: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-09-10 12:24:53.403689: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2900000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 12:24:54.094545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-09-10 12:24:55.527449: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-09-10 12:24:55.804374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 9s 189ms/step - loss: 65.6709 - val_loss: 17.6982\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 3s 117ms/step - loss: 18.9983 - val_loss: 16.6158\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 3s 117ms/step - loss: 15.6905 - val_loss: 14.2345\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 3s 117ms/step - loss: 13.3973 - val_loss: 12.0044\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 3s 116ms/step - loss: 11.1967 - val_loss: 9.5864\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 3s 117ms/step - loss: 9.4747 - val_loss: 9.5329\n",
      "Epoch 7/200\n",
      " 1/27 [>.............................] - ETA: 2s - loss: 9.0008"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m  tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(model_path, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m callbacks\u001b[38;5;241m=\u001b[39m[early_stopings,checkpoint]\n\u001b[0;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_all\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1105\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1105\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1107\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:454\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 454\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:296\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(hook))\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:316\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    314\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    319\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(callback, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_supports_tf_logs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m numpy_logs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Only convert once.\u001b[39;00m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:1020\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1020\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:1084\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1083\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1085\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py:514\u001b[0m, in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m    512\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t  \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py:510\u001b[0m, in \u001b[0;36mto_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    509\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, ops\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 510\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m    512\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1071\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \n\u001b[1;32m   1050\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1071\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1037\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1036\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1038\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m     six\u001b[38;5;241m.\u001b[39mraise_from(core\u001b[38;5;241m.\u001b[39m_status_to_exception(e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmessage), \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_path=\"../../models/base_model/u_net_dist.h5\"\n",
    "\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "history = base_model.fit(X_all,y_all, epochs=200, \n",
    "                         validation_data=(X_all,y_all),\n",
    "                         workers=-1,batch_size=16,\n",
    "                         callbacks=callbacks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aecdba-4cf2-4f0c-b0a9-a4edf26494de",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e8ce0bf-2eba-4951-8d10-4d0e6892b2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_model = tf.keras.models.load_model('../../models/base_model/u_net_dist_final.h5', custom_objects={'custom_rmse':custom_rmse})\n",
    "predicted_image= cnn_model.predict(X_all,verbose=1)\n",
    "predicted_image[y_all==0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b72f3417-64a5-4766-89ba-b5dbfcff625a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0010754e+07, 3.6302500e+05, 2.0546840e+06, 1.1640878e+07,\n",
       "        2.9447960e+06, 2.2366000e+05, 3.0184000e+04, 9.1380000e+03,\n",
       "        3.2130000e+03, 4.6800000e+02]),\n",
       " array([ -0.80052453,  23.543337  ,  47.8872    ,  72.231064  ,\n",
       "         96.57492   , 120.918785  , 145.26265   , 169.6065    ,\n",
       "        193.95036   , 218.29424   , 242.63809   ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predicted_image.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9391fcdf-da2b-4d38-90df-93297fa31034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.958678461381212, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(custom_rmse(predicted_image,y_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f4e04ba-ab19-4f29-b92c-69eef6b0d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_true_all = np.empty((0,180,360))\n",
    "y_pred_all = np.empty((0,180,360))\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    tmp = i+1\n",
    "    dir_name = dir + \"member_\" + str(data_nums[i])\n",
    "    chl,mld,sss,sst,u10,xco2,icefrac,patm,pco2t2 = read_xarray(dir_name,num =data_nums[i])\n",
    "    y_true,y_pred = inverse_scale_image(predicted_image[421*(tmp-1):421*tmp],pco2t2.pCO2.data)\n",
    "    y_true_all = np.concatenate((y_true_all, y_true))\n",
    "    y_pred_all = np.concatenate((y_pred_all, y_pred))\n",
    "\n",
    "\n",
    "print(\"y_shapes:\", y_true_all.shape, y_pred_all.shape)\n",
    "print(\"Full RMSE score:\")\n",
    "a=custom_rmse(y_pred_all,y_true_all)\n",
    "print(a.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f881b-211e-410a-8431-ce8d304e538e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using the prediction as input in ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "523ddf86-ab51-40c5-a699-a28f54f6d0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((420, 1, 180, 360, 6), (420, 1, 180, 360, 1))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 1\n",
    "X_all_conv = np.empty((0, K, 180, 360, 6))\n",
    "y_all_conv = np.empty((0, K, 180, 360, 1))\n",
    "X_index=np.lib.stride_tricks.sliding_window_view(range(421),K)\n",
    "\n",
    "tmp = 1\n",
    "\n",
    "for i in range(1):\n",
    "    dir_name = dir + \"member_\" + str(data_nums[i])\n",
    "    chl,mld,sss,sst,u10,xco2,icefrac,patm,pco2 = read_xarray(dir_name,num=data_nums[i])\n",
    "\n",
    "    chl_images = preprocess_image_reduced(chl.Chl.data)\n",
    "    sss_images = preprocess_image_reduced(sss.SSS.data)\n",
    "    sst_images = preprocess_image_reduced(sst.SST.data)\n",
    "    xco2_images = preprocess_image_reduced(xco2.XCO2.data,xco2=True)\n",
    "    pco2 = preprocess_image_reduced(pco2.pCO2.data)\n",
    "    dist_map = preprocess_image_reduced(dist_map)\n",
    "    \n",
    "    y = np.expand_dims(pco2[X_index][1:], axis=4)\n",
    "    \n",
    "    X = np.dstack((chl_images, dist_map, sss_images, sst_images, xco2_images,predicted_image[421*(tmp-1):421*tmp]))\n",
    "    tmp+=1\n",
    "    X = X.reshape((421,180,360,6),order='F')\n",
    "    X = X[X_index][:-1]\n",
    "    \n",
    "    X_all_conv = np.concatenate((X_all_conv, X))\n",
    "    y_all_conv = np.concatenate((y_all_conv, y))\n",
    "\n",
    "\n",
    "shuffle_ind = (np.arange(X_all_conv.shape[0]))\n",
    "np.random.shuffle(shuffle_ind)\n",
    "X_all_conv = np.array(X_all_conv)[shuffle_ind.astype(int)]\n",
    "y_all_conv = np.array(y_all_conv)[shuffle_ind.astype(int)]\n",
    "\n",
    "X_all_conv.shape, y_all_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee5ad845-5342-46c1-8bec-500e0463b85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 180, 360, 6)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE=X_all_conv[0].shape\n",
    "OUTPUT_SHAPE=y_all_conv[0].shape\n",
    "\n",
    "INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5397ccfa-7585-4ad8-a938-5423ace51d94",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc371398-7716-4629-afc6-a683bed25845",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "DefaultConvLSTM2D = partial(keras.layers.ConvLSTM2D,\n",
    "                        filters=32, kernel_size=(5, 5),\n",
    "                        padding=\"same\",return_sequences=True,\n",
    "                        activation=\"elu\",)\n",
    "\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConvLSTM2D(input_shape=INPUT_SHAPE),\n",
    "    DefaultConvLSTM2D(kernel_size=(4,4)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    DefaultConvLSTM2D(kernel_size=(2,2)),\n",
    "    keras.layers.Conv3D(filters = 1, kernel_size=(3,3,3),activation=\"elu\", padding=\"same\")\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=custom_rmse, optimizer=keras.optimizers.Adam(\n",
    "        learning_rate=0.001),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ae823f68-2fc7-4b34-a16a-6f3fb51cdc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 1, 180, 360, 32)   121728    \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 1, 180, 360, 32)   131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1, 180, 360, 32)   128       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, 1, 180, 360, 32)   32896     \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 1, 180, 360, 1)    865       \n",
      "=================================================================\n",
      "Total params: 286,817\n",
      "Trainable params: 286,753\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eb2a2f-9b6c-445a-a6ac-b2de8514f04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "53/53 [==============================] - 27s 383ms/step - loss: 78.4828 - val_loss: 111.5323\n",
      "Epoch 2/50\n",
      "53/53 [==============================] - 19s 355ms/step - loss: 11.0852 - val_loss: 12.8338\n",
      "Epoch 3/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 8.3139 - val_loss: 12.4208\n",
      "Epoch 4/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 7.7469 - val_loss: 19.5186\n",
      "Epoch 5/50\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 7.1362 - val_loss: 21.5166\n",
      "Epoch 6/50\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 6.7673 - val_loss: 16.5844\n",
      "Epoch 7/50\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 6.6387 - val_loss: 14.8207\n",
      "Epoch 8/50\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 6.5147 - val_loss: 16.3115\n",
      "Epoch 9/50\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 6.3363 - val_loss: 10.6642\n",
      "Epoch 10/50\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 6.3023 - val_loss: 11.4643\n",
      "Epoch 11/50\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 6.4611 - val_loss: 7.1204\n",
      "Epoch 12/50\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 6.0415 - val_loss: 6.0525\n",
      "Epoch 13/50\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 5.9980 - val_loss: 6.2945\n",
      "Epoch 14/50\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 6.0164 - val_loss: 6.7936\n",
      "Epoch 15/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 6.0218 - val_loss: 5.9628\n",
      "Epoch 16/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.9024 - val_loss: 5.8382\n",
      "Epoch 17/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.9489 - val_loss: 6.3551\n",
      "Epoch 18/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.8377 - val_loss: 5.7952\n",
      "Epoch 19/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.7269 - val_loss: 5.7456\n",
      "Epoch 20/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.9185 - val_loss: 6.1521\n",
      "Epoch 21/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.8242 - val_loss: 6.7472\n",
      "Epoch 22/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.7360 - val_loss: 5.6946\n",
      "Epoch 23/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.7481 - val_loss: 6.1346\n",
      "Epoch 24/50\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 5.7632 - val_loss: 6.3687\n",
      "Epoch 25/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.6320 - val_loss: 6.2271\n",
      "Epoch 26/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.6760 - val_loss: 6.9381\n",
      "Epoch 27/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.7227 - val_loss: 6.7720\n",
      "Epoch 28/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.6632 - val_loss: 5.6008\n",
      "Epoch 29/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.6560 - val_loss: 5.9100\n",
      "Epoch 30/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.5683 - val_loss: 5.6091\n",
      "Epoch 31/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.6556 - val_loss: 5.5365\n",
      "Epoch 32/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.5237 - val_loss: 6.4866\n",
      "Epoch 33/50\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 5.5358 - val_loss: 5.8463\n",
      "Epoch 34/50\n",
      "53/53 [==============================] - ETA: 0s - loss: 5.5721"
     ]
    }
   ],
   "source": [
    "model_path=f\"../../models/ConvLSTM_with_pco2_{K}mon.h5\"\n",
    "\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=6, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "\n",
    "# Fit the model to the training data.\n",
    "hist = model.fit(\n",
    "    X_all_conv,\n",
    "    y_all_conv,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_all_conv,y_all_conv),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f52c67-4db3-4db4-b93e-83d1918f894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the masking continents for continent works better for pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3b8a1-f3bb-4087-863b-1d1afa12ab0f",
   "metadata": {},
   "source": [
    "### Result for CONVLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8e7d13-e411-4963-9b4e-25dbbb397701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_scale_image_nfp(arr, df):\n",
    "    \"\"\"\n",
    "    inverse_scale_image(arr, df):\n",
    "    - inverses the pco2 scaling\n",
    "    \"\"\"\n",
    "    \n",
    "    old_min = np.nanmin(df)\n",
    "    old_max = np.nanmax(df)\n",
    "\n",
    "    y_pred = arr*(old_max-old_min)/255+old_min\n",
    "    \n",
    "    tmp=np.nan_to_num(df[X_index][1:])\n",
    "    y_true=np.expand_dims(tmp,axis=4)\n",
    "    y_pred[y_true==0]=0\n",
    "    return y_true,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68a6b8-f1ec-42c8-9aab-4e62252bccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "convlstm_model_path = f\"../../models/ConvLSTM_with_pco2_{K}mon.h5\"\n",
    "convlstm_model = tf.keras.models.load_model(convlstm_model_path, custom_objects={'custom_rmse':custom_rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf4035-1e98-481b-8f91-18c8fae0b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_name = \"../../data/member_009\"\n",
    "chl,mld,sss,sst,u10,xco2,icefrac,patm,pco2t2 = read_xarray(\n",
    "    dir_name,num=\"009\")\n",
    "\n",
    "tmp = np.nan_to_num(pco2t2.pCO2.data[X_index][1:])\n",
    "\n",
    "y_true_full = np.expand_dims(tmp,axis=4)\n",
    "print(y_true_full.shape)\n",
    "coord = (y_true_full==0.0)\n",
    "\n",
    "chl_images = preprocess_image_reduced(chl.Chl.data)\n",
    "sss_images = preprocess_image_reduced(sss.SSS.data)\n",
    "sst_images = preprocess_image_reduced(sst.SST.data)\n",
    "mld_images = preprocess_image_reduced(mld.MLD.data)\n",
    "xco2_images = preprocess_image_reduced(xco2.XCO2.data,xco2=True)\n",
    "y1 = preprocess_image_reduced(pco2t2.pCO2.data)\n",
    "dist_map = preprocess_image_reduced(dist_map)\n",
    "X1 = np.dstack((chl_images, dist_map, sss_images, sst_images, xco2_images))\n",
    "X1 = X1.reshape((421,180,360,5),order='F')\n",
    "\n",
    "predicted_image= cnn_model.predict(X1,verbose=1)\n",
    "predicted_image[y1==0]=0.0\n",
    "\n",
    "\n",
    "X_tmp = np.dstack((chl_images, dist_map, sss_images, sst_images, xco2_images,predicted_image))\n",
    "X_tmp= X_tmp.reshape((421,180,360,6),order='F')\n",
    "\n",
    "\n",
    "X2 = X_tmp[X_index][:-1]\n",
    "\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866bce0a-0020-4ef1-b9bb-ac90cbbe8e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_frames = convlstm_model.predict(X2)\n",
    "\n",
    "y_true,y_pred=inverse_scale_image_nfp(predicted_frames,pco2t2.pCO2.data)  \n",
    "y_pred[coord]=0.0\n",
    "y_true[coord]=0.0\n",
    "\n",
    "print(\"Full RMSE score:\")\n",
    "a=custom_rmse(y_true[:,K-1],y_pred[:,K-1]) # RMSE 3 month: 14.52 # RMSE 6 month: 13.133677\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa2631-115f-4598-b8a1-9d77114ba83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=y1[X_index][:-1]\n",
    "y1 = np.expand_dims(y1,axis=4)\n",
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d83745-11ee-4d1e-a01d-ffe74ad2eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2677c9d7-db27-4d08-81ca-2142cb548e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_frames[:,K-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e94f24-8adb-468a-ae95-60c7763e554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true[coord]=np.nan\n",
    "y_pred[coord]=np.nan\n",
    "\n",
    "res = y_true[:,K-1]-y_pred[:,K-1]\n",
    "\n",
    "avg_time_res_convlstm = np.nanmean(res, axis=(1,2,3))\n",
    "print(avg_time_res_convlstm.shape)\n",
    "\n",
    "fig = pyplot.figure(figsize = (10,10))\n",
    "pyplot.subplot(211)\n",
    "plot_acf(avg_time_res_convlstm, ax=pyplot.gca())\n",
    "pyplot.subplot(212)\n",
    "plot_pacf(avg_time_res_convlstm, ax=pyplot.gca())\n",
    "\n",
    "fig.suptitle(f\"Residual ACF & PACF for ConvLSTM {K} month- CESM\")\n",
    "\n",
    "plt.savefig(f\"../../assets/figure7_convLSTM_cesm_acf_{K}mon.jpg\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8640f34e-81ab-4def-bd3c-a2f1c25afedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels = []\n",
    "start_year = 2000\n",
    "\n",
    "for i in range(len(avg_time_res_convlstm[218:])):\n",
    "    if i%12==0:\n",
    "        xlabels.append(str(start_year))\n",
    "        start_year+=1\n",
    "    else:\n",
    "        xlabels.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35140ee2-0e02-4913-af0f-0b09851ed67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure(figsize = (20,5))\n",
    "plt.plot(avg_time_res_convlstm[218:])\n",
    "plt.xticks(ticks=range((415-218)),labels=xlabels,rotation=40)\n",
    "plt.axhline(y = 0.0,color = 'r', linestyle = '-')\n",
    "fig.suptitle(f\"ConvLSTM {K} month - Residual over Time\")\n",
    "plt.savefig(f\"../../assets/figure7_convLSTM_residual_{K}mon.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3bffb-bc53-45b2-8fe9-9e313af1ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(avg_time_res_convlstm), np.var(avg_time_res_convlstm)\n",
    "# 3 mon: (0.19049866223339668, 4.744850814381859)\n",
    "# 6 mon: (0.08857827863591704, 3.2171045340551534)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab306366-c190-46da-b1bd-851c1acdc698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
