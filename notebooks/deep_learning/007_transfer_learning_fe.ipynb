{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "410c432d-7d44-422a-8538-3dc104a5e7c4",
   "metadata": {},
   "source": [
    "## Transfer Learning from CNN LSTM\n",
    "\n",
    "\n",
    "### Method 2\n",
    "https://medium.com/@slaxman/perform-regression-using-transfer-learning-to-predict-house-prices-97e432a66ba5\n",
    "\n",
    "- separate chain of numerical data vs. image data as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd6931ab-a285-43e2-9a6a-2623a901ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv/lib/python3.8/site-packages/xarray/backends/cfgrib_.py:27: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n",
      "2022-02-09 14:32:35.613149: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64\n",
      "2022-02-09 14:32:35.613795: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import os\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "sys.path.insert(0, '../../src')\n",
    "from utils import df_to_xarray,read_xarray,inverse_scale_image, get_point_prediction\n",
    "\n",
    "sys.path.insert(0, '../../src/preprocess')\n",
    "from data_preprocess import preprocess_image_reduced,preprocess_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8a071b-8e33-447d-8f14-58c9d6fc95c5",
   "metadata": {},
   "source": [
    "## Numeric Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e626156b-6ff2-4ecd-aaef-831af8a2dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "dir_name=\"../../data/data1\"\n",
    "chl,mld,sss,sst,u10,fg_co2,xco2,icefrac,patm,pco2=read_xarray(dir_name)\n",
    "\n",
    "# Creating one singular df\n",
    "data_read=xr.merge([mld.MLD,mld.MLD_socat,sst.SST,sst.SST_socat,sss.SSS,sss.SSS_socat,xco2])\n",
    "tmp_data=data_read.to_dataframe().reset_index()\n",
    "\n",
    "tmp_data=tmp_data.drop(columns=['bnds','TLONG', 'TLAT', 'time_bnds'])\n",
    "\n",
    "chl_data=chl.Chl.to_dataframe().reset_index()\n",
    "chl_data_socat=chl.Chl_socat.to_dataframe().reset_index()\n",
    "pco2_data=pco2.pCO2.to_dataframe().reset_index()\n",
    "pco2_data_socat=pco2.pCO2_socat.to_dataframe().reset_index()\n",
    "\n",
    "tmp_data[\"Chl_socat\"]=chl_data_socat[\"Chl_socat\"]\n",
    "tmp_data[\"Chl\"]=chl_data[\"Chl\"]\n",
    "tmp_data[\"pCO2_socat\"]=pco2_data_socat[\"pCO2_socat\"]\n",
    "tmp_data[\"pCO2\"]=pco2_data[\"pCO2\"]\n",
    "\n",
    "features_socat = ['time', 'xlon', 'ylat','MLD_socat', 'SST_socat', 'SSS_socat','Chl_socat', 'XCO2','pCO2_socat']\n",
    "features = ['time', 'xlon', 'ylat','MLD','SST','SSS','Chl','XCO2','pCO2']\n",
    "\n",
    "# create separate dataframe for socat\n",
    "combined_socat=tmp_data.loc[:,features_socat]\n",
    "combined=tmp_data.loc[:,features]\n",
    "\n",
    "# drop rows where pco2 or pco2_socat == NA\n",
    "combined_socat.dropna(subset = [\"pCO2_socat\"], inplace=True)\n",
    "combined_socat= combined_socat[combined_socat['pCO2_socat']!=0]\n",
    "combined.dropna(subset = [\"pCO2\"], inplace=True)\n",
    "combined= combined[combined['pCO2']!=0]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "179f13d3-9afb-4420-af7d-e6ce7e57e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_id = dict()\n",
    "\n",
    "times=np.unique(combined_socat['time'])\n",
    "\n",
    "for t in range(len(times)):\n",
    "    time=times[t]\n",
    "    time_to_id[time]=t\n",
    "\n",
    "combined_socat['time']=combined_socat['time'].map(time_to_id)\n",
    "combined['time']=combined['time'].map(time_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f116ed6-4b9e-4412-a684-06ab0b4af34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_socat=combined_socat.iloc[:,3:-1]\n",
    "X=combined.iloc[:,3:-1]\n",
    "y=combined.loc[:,'pCO2']\n",
    "y_socat=combined_socat.loc[:,'pCO2_socat']\n",
    "\n",
    "X_socat=num_pipeline.fit_transform(X_socat)\n",
    "X=num_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8a9466-924d-463f-aa01-66b02e41bd7e",
   "metadata": {},
   "source": [
    "## Image Data and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37fcb4cc-475b-4825-a3ae-d4bc3f0d7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as kb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def custom_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    custom_rmse(y_true, y_pred)\n",
    "    calculates root square mean value with focusing only on the ocean\n",
    "    \"\"\"\n",
    "    y_pred = y_pred[y_true != 0]\n",
    "    y_true = y_true[y_true != 0]\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    \n",
    "    return K.sqrt(K.mean(tf.math.squared_difference(y_pred, y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db2375f1-4244-4f54-8dfb-85950c2c1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../../src/preprocess')\n",
    "from data_preprocess import preprocess_image_reduced,preprocess_images\n",
    "\n",
    "\n",
    "# Image component \n",
    "dir_name=\"../../data/data1\"\n",
    "val_dir_name=\"../../data/data2\"\n",
    "\n",
    "data,pco2 = preprocess_images(dir_name)\n",
    "data_socat, pco2_socat = preprocess_images(dir_name, socat = True)\n",
    "val_data,val_pco2 = preprocess_images(val_dir_name,\"035\")\n",
    "val_data_socat, val_pco2_socat = preprocess_images(val_dir_name,\"035\", socat = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65c6ad21-acef-4084-a7d3-1966adc01ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data issue\n",
    "#data_socat[combined_socat['time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c28b2bbc-6f1b-45a0-910f-76fe8240ab2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 360, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE=data_socat[0].shape\n",
    "\n",
    "INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb3b859-1b99-4b88-ab14-84bc7c4c1b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 14:34:53.037668: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-09 14:34:53.138997: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64\n",
      "2022-02-09 14:34:53.170623: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-09 14:34:53.186414: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (g020): /proc/driver/nvidia/version does not exist\n",
      "2022-02-09 14:34:53.235912: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-09 14:34:53.246556: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.models.load_model('../../models/base_model/base_model_new.h5', custom_objects={'custom_rmse':custom_rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57478198-c672-47a7-bd41-5e73d923f46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 360, 64)      8064      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 180, 360, 64)      102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 60, 120, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 120, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 120, 128)      204928    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 120, 128)      409728    \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 180, 360, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 180, 360, 64)      204864    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 180, 360, 2)       3202      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 180, 360, 1)       3         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 180, 360)          0         \n",
      "=================================================================\n",
      "Total params: 933,253\n",
      "Trainable params: 933,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "745eb940-6eb9-4dbd-b212-088f8df998f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c914a-fcca-4a23-8f34-840a30fdca07",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/images/transfer_learning\n",
    "\n",
    "## Taking multiple Inputs\n",
    "https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40730345-f10d-4bd2-943e-c46d1d40f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "input_numeric = keras.layers.Input(shape=(32,))\n",
    "\n",
    "input_image = keras.layers.Input(shape=INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d69a9126-6b34-42f8-b413-f41a35d70aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image portion\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.layers[-2].output)\n",
    "dense_1= keras.layers.Dense(512, activation=\"elu\")(avg)\n",
    "dense_2 = keras.layers.Dense(64, activation=\"elu\")(dense_1)\n",
    "class_output = keras.layers.Dense(8, activation=\"elu\")(dense_2)\n",
    "\n",
    "image_model = keras.models.Model(inputs=base_model.input, outputs=class_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01ea17ac-e39b-4e32-bdab-13fee20336da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric portion\n",
    "y = keras.layers.BatchNormalization()(input_numeric)\n",
    "y = keras.layers.Dense(1024, activation=\"elu\")(y)\n",
    "y = keras.layers.Dropout(0.2)(y)\n",
    "\n",
    "y = keras.layers.Dense(512, activation=\"elu\")(y)\n",
    "y = keras.layers.Dropout(0.25)(y)\n",
    "\n",
    "y = keras.layers.Dense(8, activation=\"elu\")(y)\n",
    "\n",
    "\n",
    "numeric_model = keras.models.Model(inputs=input_numeric, outputs=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c4c8dea-44ed-432d-bd33-1791ed71bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = keras.layers.concatenate([image_model.output, numeric_model.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4846ae7-0832-4001-b979-aae4cc27f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = keras.layers.Dense(2, activation=\"relu\")(combined)\n",
    "final = keras.layers.Dense(1, activation=\"linear\")(final)\n",
    "\n",
    "\n",
    "final_model = keras.models.Model(inputs=[image_model.input, numeric_model.input], outputs=final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f971fe65-b266-405b-8793-c371887a8535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv2d_input (InputLayer)       [(None, 180, 360, 5) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 180, 360, 64) 8064        conv2d_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 180, 360, 64) 102464      conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 60, 120, 64)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 60, 120, 64)  0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 60, 120, 128) 204928      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 60, 120, 128) 409728      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 180, 360, 128 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 180, 360, 64) 204864      up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 180, 360, 2)  3202        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32)           128         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 180, 360, 1)  3           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1024)         33792       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1)            0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1024        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           32832       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            520         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 8)            4104        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16)           0           dense_2[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            34          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            3           dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,530,490\n",
      "Trainable params: 597,173\n",
      "Non-trainable params: 933,317\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffbfc156-c6c4-4eec-b2e7-019f97de514b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 245577, 421\n  y sizes: 245577\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2614579/4259965426.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m final_model.fit(\n\u001b[0m\u001b[1;32m     17\u001b[0m     x=[X_socat,data_socat], y=y_socat,epochs=epochs, batch_size=batch_size,callbacks=callbacks)\n",
      "\u001b[0;32m/burg/glab/users/sk4973/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/burg/glab/users/sk4973/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/burg/glab/users/sk4973/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/burg/glab/users/sk4973/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1527\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[1;32m   1528\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 245577, 421\n  y sizes: 245577\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model_path=\"../../models/transfer_CNN_feature.h5\"\n",
    "\n",
    "\n",
    "final_model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam())\n",
    "\n",
    "\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "\n",
    "final_model.fit(\n",
    "    x=[X_socat,data_socat], y=y_socat,epochs=epochs, batch_size=batch_size,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c3d3f-8e7d-42d5-bdab-391f8923701e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
