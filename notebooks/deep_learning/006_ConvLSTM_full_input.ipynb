{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "012f80e3-065f-4481-8b61-0b16c778386f",
   "metadata": {},
   "source": [
    "## generate previous frames with pCO2 and fit it against ConvLSTM for multiple members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c497b4-9499-4832-aed7-d1c3b9d4b5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/xarray/backends/cfgrib_.py:27: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n",
      "2022-09-12 14:25:55.275638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '../../src')\n",
    "\n",
    "from utils import df_to_xarray,read_xarray, custom_rmse\n",
    "\n",
    "sys.path.insert(0, '../../src/preprocess')\n",
    "from data_preprocess import preprocess_image_reduced,preprocess_images_nfp, inverse_scale_frame\n",
    "from data_preprocess import preprocess_images, inverse_scale_image, preprocess_image_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ea67d-8bc2-422f-8c39-0de87dd0ed5c",
   "metadata": {},
   "source": [
    "### Previous Frame generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8115c973-ef73-46a6-b8b7-9142c659c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_map = pd.read_csv(\"../../src/dist_map.csv\",header=None).to_numpy()\n",
    "dist_map = np.roll(np.fliplr(dist_map),180)\n",
    "dist_map = np.repeat(dist_map[np.newaxis, :, : ], 421, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a572ea-5c8a-4062-ad05-0d655167249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "dir = \"../../data/\"\n",
    "dir_name = \"../../data/member_001\"\n",
    "data_nums = [\"001\", \"002\", \"009\", \"010\", \"011\", \"012\", \"013\", \"014\", \"015\", \"016\", \"017\", \"018\", \"020\",\n",
    "             \"021\", \"023\", \"024\", \"025\", \"030\", \"031\", \"034\", \"035\", \"101\", \"102\", \"103\", \"104\"]\n",
    "\n",
    "X_all = np.empty((0, 180, 360, 5))\n",
    "y_all = np.empty((0, 180, 360))\n",
    "\n",
    "for i in range(3):\n",
    "    dir_name = dir + \"member_\" + str(data_nums[i])\n",
    "    chl,mld,sss,sst,u10,xco2,icefrac,patm,pco2 = read_xarray(dir_name,num =data_nums[i])\n",
    "    \n",
    "    chl_images = preprocess_image_reduced(chl.Chl.data)\n",
    "    sss_images = preprocess_image_reduced(sss.SSS.data)\n",
    "    sst_images = preprocess_image_reduced(sst.SST.data)\n",
    "    mld_images = preprocess_image_reduced(mld.MLD.data)\n",
    "    xco2_images = preprocess_image_reduced(xco2.XCO2.data,xco2=True)\n",
    "    y1 = preprocess_image_reduced(pco2.pCO2.data)\n",
    "    dist_map = preprocess_image_reduced(dist_map)\n",
    "    X1 = np.dstack((chl_images, dist_map, sss_images, sst_images, xco2_images))\n",
    "    #X1 = np.dstack((chl_images, mld_images, sss_images, sst_images, xco2_images))\n",
    "    X1 = X1.reshape((421,180,360,5),order='F')\n",
    "    \n",
    "    X_all = np.concatenate((X_all, X1))\n",
    "    y_all = np.concatenate((y_all, y1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e231214a-a785-4872-8145-610401a04b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180, 360, 5), (1263, 180, 360, 5), (1263, 180, 360))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE=X_all[0].shape\n",
    "OUTPUT_SHAPE=y_all[0].shape\n",
    "\n",
    "INPUT_SHAPE, X_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71dcf66-0fb2-475f-830f-4e0e44cec5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=5,activation='elu',\n",
    "                        padding=\"SAME\")\n",
    "\n",
    "base_model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=32, input_shape=INPUT_SHAPE),\n",
    "    DefaultConv2D(filters=32),\n",
    "    keras.layers.MaxPooling2D(pool_size=3),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    DefaultConv2D(filters=64),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.MaxPooling2D(pool_size=3),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.UpSampling2D(size=3),\n",
    "    DefaultConv2D(filters=64),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.UpSampling2D(size=3),\n",
    "    DefaultConv2D(filters=32),\n",
    "    DefaultConv2D(filters=2),\n",
    "    DefaultConv2D(filters=1,kernel_size=1),\n",
    "    keras.layers.Reshape(OUTPUT_SHAPE)\n",
    "])\n",
    "\n",
    "myLearnRate=0.0005\n",
    "custom_opt = tf.keras.optimizers.Adam(learning_rate=myLearnRate)\n",
    "\n",
    "#rmse 13\n",
    "\n",
    "\n",
    "\n",
    "base_model.compile(loss=custom_rmse, optimizer=custom_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba4bec-c490-46fe-9724-efbf9f55cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_path=\"../../models/base_model/u_net_dist.h5\"\n",
    "\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "history = base_model.fit(X_all,y_all, epochs=200, \n",
    "                         validation_data=(X_all,y_all),\n",
    "                         workers=-1,batch_size=16,\n",
    "                         callbacks=callbacks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e8ce0bf-2eba-4951-8d10-4d0e6892b2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 6s 143ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_model = tf.keras.models.load_model('../../models/base_model/u_net_dist.h5', custom_objects={'custom_rmse':custom_rmse})\n",
    "predicted_image= cnn_model.predict(X_all,verbose=1)\n",
    "predicted_image[y_all==0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9391fcdf-da2b-4d38-90df-93297fa31034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.3854419655263928, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(custom_rmse(predicted_image,y_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f4e04ba-ab19-4f29-b92c-69eef6b0d926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_shapes: (1263, 180, 360) (1263, 180, 360)\n",
      "Full RMSE score:\n",
      "10.189230414266\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_true_all = np.empty((0,180,360))\n",
    "y_pred_all = np.empty((0,180,360))\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    tmp = i+1\n",
    "    dir_name = dir + \"member_\" + str(data_nums[i])\n",
    "    chl,mld,sss,sst,u10,xco2,icefrac,patm,pco2t2 = read_xarray(dir_name,num =data_nums[i])\n",
    "    y_true,y_pred = inverse_scale_image(predicted_image[421*(tmp-1):421*tmp],pco2t2.pCO2.data)\n",
    "    y_true_all = np.concatenate((y_true_all, y_true))\n",
    "    y_pred_all = np.concatenate((y_pred_all, y_pred))\n",
    "\n",
    "\n",
    "print(\"y_shapes:\", y_true_all.shape, y_pred_all.shape)\n",
    "print(\"Full RMSE score:\")\n",
    "a=custom_rmse(y_pred_all,y_true_all)\n",
    "print(a.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f881b-211e-410a-8431-ce8d304e538e",
   "metadata": {},
   "source": [
    "### Using the prediction as input in ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ddf86-ab51-40c5-a699-a28f54f6d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_conv = np.empty((0, 3, 180, 360, 6))\n",
    "y_all_conv = np.empty((0, 3, 180, 360, 1))\n",
    "X_index=np.lib.stride_tricks.sliding_window_view(range(421),3)\n",
    "\n",
    "tmp = 1\n",
    "\n",
    "for i in range(3):\n",
    "    dir_name = dir + \"member_\" + str(data_nums[i])\n",
    "    chl,mld,sss,sst,u10,xco2,icefrac,patm,pco2 = read_xarray(dir_name,num=data_nums[i])\n",
    "\n",
    "    chl_images = preprocess_image_reduced(chl.Chl.data)\n",
    "    sss_images = preprocess_image_reduced(sss.SSS.data)\n",
    "    sst_images = preprocess_image_reduced(sst.SST.data)\n",
    "    xco2_images = preprocess_image_reduced(xco2.XCO2.data,xco2=True)\n",
    "    pco2 = preprocess_image_reduced(pco2.pCO2.data)\n",
    "    dist_map = preprocess_image_reduced(dist_map)\n",
    "    \n",
    "    y = np.expand_dims(pco2[X_index][1:], axis=4)\n",
    "    \n",
    "    X = np.dstack((chl_images, dist_map, sss_images, sst_images, xco2_images,predicted_image[421*(tmp-1):421*tmp]))\n",
    "    tmp+=1\n",
    "    X = X.reshape((421,180,360,6),order='F')\n",
    "    X = X[X_index][:-1]\n",
    "    \n",
    "    X_all_conv = np.concatenate((X_all_conv, X))\n",
    "    y_all_conv = np.concatenate((y_all_conv, y))\n",
    "\n",
    "\n",
    "shuffle_ind = (np.arange(X_all_conv.shape[0]))\n",
    "np.random.shuffle(shuffle_ind)\n",
    "X_all_conv = np.array(X_all_conv)[shuffle_ind.astype(int)]\n",
    "y_all_conv = np.array(y_all_conv)[shuffle_ind.astype(int)]\n",
    "\n",
    "X_all_conv.shape, y_all_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5ad845-5342-46c1-8bec-500e0463b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE=X_all_conv[0].shape\n",
    "OUTPUT_SHAPE=y_all_conv[0].shape\n",
    "\n",
    "INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc371398-7716-4629-afc6-a683bed25845",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "DefaultConvLSTM2D = partial(keras.layers.ConvLSTM2D,\n",
    "                        filters=32, kernel_size=(5, 5),\n",
    "                        padding=\"same\",return_sequences=True,\n",
    "                        activation=\"elu\",)\n",
    "\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConvLSTM2D(input_shape=INPUT_SHAPE),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    DefaultConvLSTM2D(kernel_size=(5,5)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    DefaultConvLSTM2D(kernel_size=(3,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    DefaultConvLSTM2D(kernel_size=(1,1)),\n",
    "    keras.layers.Conv3D(filters = 1, kernel_size=(3,3,3),activation=\"elu\", padding=\"same\")\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=custom_rmse, optimizer=keras.optimizers.Adam(\n",
    "        learning_rate=0.001,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.99),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82eb2a2f-9b6c-445a-a6ac-b2de8514f04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - 244s 1s/step - loss: 48.4658 - val_loss: 27.8106\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 234s 1s/step - loss: 6.6609 - val_loss: 8.9139\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 245s 2s/step - loss: 5.5641 - val_loss: 6.6700\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 225s 1s/step - loss: 5.3254 - val_loss: 4.8809\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 221s 1s/step - loss: 4.7374 - val_loss: 9.2016\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 219s 1s/step - loss: 4.6603 - val_loss: 4.2304\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 204s 1s/step - loss: 4.7357 - val_loss: 7.2933\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 205s 1s/step - loss: 4.2834 - val_loss: 4.3098\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 211s 1s/step - loss: 4.2526 - val_loss: 4.4536\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 228s 1s/step - loss: 3.9962 - val_loss: 4.0167\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 217s 1s/step - loss: 4.1911 - val_loss: 4.4834\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 208s 1s/step - loss: 4.2959 - val_loss: 3.7432\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 204s 1s/step - loss: 4.0887 - val_loss: 3.9042\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 204s 1s/step - loss: 3.9781 - val_loss: 4.0556\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 204s 1s/step - loss: 3.8813 - val_loss: 3.6164\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 204s 1s/step - loss: 3.8054 - val_loss: 3.8718\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 205s 1s/step - loss: 3.7241 - val_loss: 3.5565\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 242s 2s/step - loss: 3.7035 - val_loss: 3.3940\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 222s 1s/step - loss: 3.7089 - val_loss: 3.7924\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 210s 1s/step - loss: 3.7731 - val_loss: 3.8441\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 212s 1s/step - loss: 3.7012 - val_loss: 3.8724\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 220s 1s/step - loss: 3.6759 - val_loss: 3.4575\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 207s 1s/step - loss: 3.5441 - val_loss: 3.6097\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 246s 2s/step - loss: 3.5615 - val_loss: 3.4044\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_path=\"../../models/ConvLSTM_with_pco2.h5\"\n",
    "\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=6, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "\n",
    "# Fit the model to the training data.\n",
    "hist = model.fit(\n",
    "    X_all_conv,\n",
    "    y_all_conv,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_all_conv,y_all_conv),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6dff83-93b2-4212-af75-cf151bcc458d",
   "metadata": {},
   "source": [
    "## transfer learning on MPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8fdbcd12-a840-42d8-b1bc-3e414f01d569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN on MPI\n",
    "cnn_model_path=\"../../models/base_model/u_net_dist.h5\"\n",
    "cnn_model = tf.keras.models.load_model(cnn_model_path, custom_objects={'custom_rmse':custom_rmse})\n",
    "\n",
    "mpi_data_path = \"../../data/mpi_001\"\n",
    "\n",
    "\n",
    "def read_xarray_mpi(dir_name=\"\",num=\"006\"):\n",
    "    '''\n",
    "     read_xarray(dir)name) opens data and returns data in xarray format for each feature mpi\n",
    "    '''\n",
    "    date=\"198201-201701\"\n",
    "  \n",
    "    file_type =\"MPI\"\n",
    "        \n",
    "    chl = xr.open_dataset(f'{dir_name}/Chl_2D_mon_{file_type}{num}_1x1_{date}.nc')\n",
    "\n",
    "    mld = xr.open_dataset(f'{dir_name}/MLD_2D_mon_{file_type}{num}_1x1_{date}.nc')\n",
    "\n",
    "    sss = xr.open_dataset(f'{dir_name}/SSS_2D_mon_{file_type}{num}_1x1_{date}.nc')\n",
    "\n",
    "    sst = xr.open_dataset(f'{dir_name}/SST_2D_mon_{file_type}{num}_1x1_{date}.nc')\n",
    "\n",
    "    xco2 = xr.open_dataset(f'../../data/member_001/XCO2_1D_mon_CESM001_native_198201-201701.nc')\n",
    "\n",
    "    pco2 = xr.open_dataset(f'{dir_name}/pCO2_2D_mon_{file_type}{num}_1x1_{date}.nc')\n",
    "\n",
    "    return chl,mld,sss,sst,xco2,pco2\n",
    "\n",
    "\n",
    "chl,mld,sss,sst,xco2,pco2 = read_xarray_mpi(mpi_data_path)\n",
    "chl_images = preprocess_image_reduced(chl.Chl.data)\n",
    "sss_images = preprocess_image_reduced(sss.SSS.data)\n",
    "sst_images = preprocess_image_reduced(sst.SST.data)\n",
    "mld_images = preprocess_image_reduced(mld.MLD.data)\n",
    "xco2_images = preprocess_image_reduced(xco2.XCO2.data,xco2=True)\n",
    "\n",
    "def pco2_socat_preprocess(arr):\n",
    "    nans=np.isnan(arr)\n",
    "    min_val=arr[~nans].min()\n",
    "    arr[nans]=min_val\n",
    "    return arr\n",
    "        \n",
    "pco2_socat_images = pco2_socat_preprocess(pco2.pCO2_socat.data)\n",
    "\n",
    "dist_map = preprocess_image_reduced(dist_map)\n",
    "    \n",
    "X_tf = np.dstack((chl_images, dist_map, sss_images, sst_images, xco2_images))\n",
    "y_tf = pco2_socat_images\n",
    "X_tf = X_tf.reshape((421,180,360,5),order='F')\n",
    "# penalize smaller variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc3404cb-55ac-4e47-a1b3-41bbf970eb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 360, 32)      4032      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 180, 360, 32)      25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 60, 120, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 120, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 120, 64)       51264     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 120, 64)       102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 20, 40, 128)       204928    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 20, 40, 128)       409728    \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 60, 120, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 60, 120, 64)       204864    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 60, 120, 64)       102464    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60, 120, 64)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 180, 360, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 180, 360, 32)      51232     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 180, 360, 2)       1602      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 180, 360, 1)       3         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 180, 360)          0         \n",
      "=================================================================\n",
      "Total params: 1,158,213\n",
      "Trainable params: 360,165\n",
      "Non-trainable params: 798,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in cnn_model.layers[:-8]:\n",
    "    layer.trainable = False\n",
    "\n",
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3cb75579-8aed-4093-bbb3-2ebedf2d4b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 4s 227ms/step - loss: 258.8431 - val_loss: 83.6659\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 79.1483 - val_loss: 50.1791\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 2s 169ms/step - loss: 46.0950 - val_loss: 31.9247\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 34.5220 - val_loss: 26.0108\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 28.8070 - val_loss: 24.3869\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 26.8457 - val_loss: 22.3754\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 25.6862 - val_loss: 21.8865\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 2s 169ms/step - loss: 24.8705 - val_loss: 20.5661\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 23.5735 - val_loss: 19.7672\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 24.1246 - val_loss: 21.3260\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 2s 169ms/step - loss: 24.2950 - val_loss: 19.3257\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 2s 169ms/step - loss: 24.3880 - val_loss: 19.1411\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 23.2678 - val_loss: 19.4981\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 22.8401 - val_loss: 18.5753\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 21.8545 - val_loss: 18.3054\n",
      "Epoch 16/200\n",
      " 6/14 [===========>..................] - ETA: 1s - loss: 21.6112"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m  tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(model_path, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     39\u001b[0m callbacks\u001b[38;5;241m=\u001b[39m[early_stopings,checkpoint]\n\u001b[0;32m---> 41\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_tf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1105\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1105\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1107\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:454\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 454\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:296\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(hook))\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:316\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    314\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    319\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(callback, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_supports_tf_logs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m numpy_logs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Only convert once.\u001b[39;00m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:1020\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1020\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:1084\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1083\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1085\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py:514\u001b[0m, in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m    512\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t  \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py:510\u001b[0m, in \u001b[0;36mto_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    509\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, ops\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 510\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m    512\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1071\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \n\u001b[1;32m   1050\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1071\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1037\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1036\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1038\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m     six\u001b[38;5;241m.\u001b[39mraise_from(core\u001b[38;5;241m.\u001b[39m_status_to_exception(e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmessage), \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "def custom_rmse2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    custom_rmse(y_true, y_pred)\n",
    "    calculates root square mean value with focusing only on the ocean\n",
    "    + difference between sss\n",
    "    \"\"\"\n",
    "    idx  = tf.not_equal(y_true, 0.0)\n",
    "    idx2  = tf.equal(y_true, 0.0)\n",
    "    \n",
    "    y_pred1 = tf.boolean_mask(y_pred,idx)\n",
    "    y_true1 = tf.boolean_mask(y_true,idx)\n",
    "    y_true1 = tf.cast(y_true1, y_pred.dtype)\n",
    "    \n",
    "    rmse1 = K.sqrt(K.mean(tf.math.squared_difference(y_pred1, y_true1),axis= -1))\n",
    "    rmse2 = tf.cast(rmse1, y_pred.dtype)\n",
    "    \n",
    "    y_pred2 = tf.boolean_mask(y_pred,idx2)\n",
    "    \n",
    "    loss2 = 10*(K.var(y_true1)/K.var(y_pred2))\n",
    "    loss2 = tf.cast(loss2, y_pred.dtype)\n",
    "    \n",
    "    return rmse1+loss2\n",
    "\n",
    "\n",
    "myLearnRate=0.001\n",
    "cnn_model.compile(\n",
    "    loss=custom_rmse2, optimizer=keras.optimizers.Adam(learning_rate=myLearnRate),\n",
    ")\n",
    "\n",
    "model_path=\"../../models/transfer_CNN.h5\"\n",
    "\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "history = cnn_model.fit(X_tf,y_tf, epochs=200, \n",
    "                         validation_data=(X_tf,y_tf),\n",
    "                         workers=-1,batch_size=32,\n",
    "                         callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac28df-2f4b-4fa9-8cbf-30ddb0166f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myLearnRate=0.0005\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "# cnn_model.compile(\n",
    "#     loss=custom_rmse, optimizer=keras.optimizers.Adam(learning_rate=myLearnRate),\n",
    "# )\n",
    "\n",
    "# model_path=\"../../models/transfer_CNN_2.h5\"\n",
    "\n",
    "# early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='min')\n",
    "# checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "# callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "# history2 = cnn_model.fit(X_tf,y_tf, epochs=200, \n",
    "#                          validation_data=(X_tf,y_tf),\n",
    "#                          workers=-1,batch_size=32,\n",
    "#                          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d15c0c89-379a-4421-8e5f-e9e689ab797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "#cnn_model = tf.keras.models.load_model('../../models/transfer_CNN_2.h5', custom_objects={'custom_rmse':custom_rmse})\n",
    "cnn_model = tf.keras.models.load_model('../../models/transfer_CNN.h5', custom_objects={'custom_rmse2':custom_rmse2})\n",
    "\n",
    "\n",
    "predicted_image = cnn_model.predict(X_tf,verbose=1)\n",
    "\n",
    "chl,mld,sss,sst,xco2,pco2 = read_xarray_mpi(mpi_data_path)\n",
    "coord = np.isnan(pco2.pCO2.data)\n",
    "predicted_image[coord] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "50daa7dd-b170-44d5-b91c-bb261ecb76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import imageio\n",
    "\n",
    "\n",
    "full_truth = pco2.pCO2.data\n",
    "full_truth[coord] = 0\n",
    "\n",
    "norm = mcolors.Normalize(vmin=0, vmax = 750)\n",
    "norm2 = mcolors.TwoSlopeNorm(vmin=-500, vmax = 500, vcenter=0)\n",
    "\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for i in range(421):\n",
    "    figure, axis = plt.subplots(1, 3,figsize=(18, 10))\n",
    "    \n",
    "    img=axis[0].imshow(np.flipud(predicted_image[i]),cmap=\"coolwarm\", interpolation=\"nearest\", norm=norm)\n",
    "    axis[0].set_title(\"prediction\")\n",
    "    plt.colorbar(img,ax=axis)\n",
    "\n",
    "    img1=axis[1].imshow(np.flipud(full_truth[i]),cmap=\"coolwarm\", interpolation=\"nearest\",norm=norm)\n",
    "    axis[1].set_title(\"true\")\n",
    "\n",
    "    img2=axis[2].imshow(np.flipud(full_truth[i]-(predicted_image[i])),cmap=\"RdBu\", norm=norm2)\n",
    "    axis[2].set_title(\"residual\")\n",
    "    plt.colorbar(img2,ax=axis)\n",
    "    \n",
    "    text = \"rmse: \"+str(np.round(np.sqrt(np.mean((full_truth[i]-predicted_image[i])**2)),2))\n",
    "    plt.text(-60, -60, text, fontsize = 20)\n",
    "    \n",
    "    filename = f'{i}.png'\n",
    "    filenames.append(filename)\n",
    "    \n",
    "    # save frame\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "with imageio.get_writer('../../assets/cnn_mpi_transfer.gif', mode='I') as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "        \n",
    "# Remove files\n",
    "for filename in set(filenames):\n",
    "    os.remove(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "513ce36d-af94-4ca8-b132-5340b050a913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.039734"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((full_truth-predicted_image)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f90094-5d63-43a3-99d6-84d9ff58dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_index=np.lib.stride_tricks.sliding_window_view(range(421),3)\n",
    "X = np.dstack((chl_images, dist_map, sss_images, sst_images, xco2_images,predicted_image))\n",
    "X = X.reshape((421,180,360,6),order='F')\n",
    "X = X[X_index][:-1]\n",
    "\n",
    "y_tf=np.expand_dims(y_tf[X_index][1:],axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f7de44-f8a7-4876-8cf3-0c787f45aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y_tf.shape # changed sliding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c3bc6-bd4c-44be-8e9d-b2aac3726c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "convlstm_model_path = \"../../models/ConvLSTM_with_pco2.h5\"\n",
    "convlstm_model = tf.keras.models.load_model(convlstm_model_path, custom_objects={'custom_rmse':custom_rmse})\n",
    "\n",
    "\n",
    "for layer in convlstm_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "convlstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36adbb2d-b7cf-4b4e-912c-a926d9280859",
   "metadata": {},
   "outputs": [],
   "source": [
    "convlstm_model.compile(\n",
    "    loss=custom_rmse, optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    ")\n",
    "\n",
    "model_path=\"../../models/transfer_CNN_LSTM.h5\"\n",
    "\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98f6b1ac-ab2f-447b-a5a4-24704af328bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 180, 360, 6) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3, 180, 360, 6), dtype=tf.float32, name='conv_lst_m2d_input'), name='conv_lst_m2d_input', description=\"created by layer 'conv_lst_m2d_input'\"), but it was called on an input with incompatible shape (None, 4, 180, 360, 6).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 180, 360, 6) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3, 180, 360, 6), dtype=tf.float32, name='conv_lst_m2d_input'), name='conv_lst_m2d_input', description=\"created by layer 'conv_lst_m2d_input'\"), but it was called on an input with incompatible shape (None, 4, 180, 360, 6).\n",
      "27/27 [==============================] - ETA: 0s - loss: 14.9483WARNING:tensorflow:Model was constructed with shape (None, 3, 180, 360, 6) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3, 180, 360, 6), dtype=tf.float32, name='conv_lst_m2d_input'), name='conv_lst_m2d_input', description=\"created by layer 'conv_lst_m2d_input'\"), but it was called on an input with incompatible shape (None, 4, 180, 360, 6).\n",
      "27/27 [==============================] - 63s 2s/step - loss: 14.8245 - val_loss: 13.8824\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 47s 2s/step - loss: 8.4581 - val_loss: 10.0300\n",
      "Epoch 3/50\n",
      " 5/27 [====>.........................] - ETA: 27s - loss: 7.7690"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mconvlstm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    853\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    858\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = convlstm_model.fit(\n",
    "    X,\n",
    "    y_tf,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X, y_tf),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c9ea1c-cade-403f-bd43-1ddad24554b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_scale_frame_socat(arr,df, X_index=[]):\n",
    "    \"\"\"\n",
    "    inverse_scale_frame(arr, df):\n",
    "    - inverses the pco2 scaling\n",
    "    \"\"\"\n",
    "    old_min = 0\n",
    "    df_tmp = df[df!=0.0]\n",
    "    old_max = np.nanmax(df_tmp)\n",
    "    y_pred = arr*(old_max-old_min)/255+old_min\n",
    "    tmp=np.nan_to_num(df[X_index][1:])\n",
    "    y_true=np.expand_dims(tmp,axis=4)\n",
    "    y_pred[y_true==0]=0\n",
    "    return y_true,y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3a625-3390-4b73-8ccd-9b456c830ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = tf.keras.models.load_model(\"../../models/transfer_CNN_LSTM.h5\", custom_objects={'custom_rmse':custom_rmse})\n",
    "\n",
    "predicted_frames= tf_model.predict(X,verbose=1)\n",
    "chl,mld,sss,sst,xco2,pco2t2 = read_xarray_mpi(mpi_data_path)\n",
    "\n",
    "\n",
    "y_true_socat,y_pred = inverse_scale_frame_socat(predicted_frames,pco2t2.pCO2_socat.data,X_index)\n",
    "\n",
    "print(\"SOCAT RMSE score:\")\n",
    "a=custom_rmse(y_pred[:,:2],y_true_socat[:,:2])\n",
    "print(a)\n",
    "\n",
    "print(\"Full RMSE score:\")\n",
    "tmp = np.nan_to_num(pco2t2.pCO2.data[X_index][1:])\n",
    "y_true_full = np.expand_dims(tmp,axis=4)\n",
    "\n",
    "a=custom_rmse(y_pred[:,:2],y_true_full[:,:2])\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78798c3-d509-4e8d-9a86-48cf9569aa22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d969e-7c24-4992-8600-58eb24cf4ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
