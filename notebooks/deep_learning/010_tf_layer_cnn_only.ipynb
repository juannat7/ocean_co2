{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d96220-a312-4867-a8cf-4d14919c3174",
   "metadata": {},
   "source": [
    "## Transfer Learning from CNN \n",
    "\n",
    "\n",
    "### Method 1\n",
    "- Data preprocess the same way for input\n",
    "- try the same thing as tf_layer2 but with unet \n",
    "\n",
    "### Bench Marks\n",
    "**Final Result for Random Forest trained on SOCAT**\n",
    "\n",
    "Test Set RMSE: 30.56 | Whole Grid Rmse: 42.12\n",
    "\n",
    "\n",
    "**Final Result for XGBoost trained on SOCAT**\n",
    "\n",
    "Test Set RMSE:28.43698261274142 | Whole Grid Rmse:37.709863752151215\n",
    "\n",
    "### Result\n",
    "\n",
    "Test Set RMSE: 15.368 | Whole Grid RMSE: ~87\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dff88d92-fe89-4a88-9152-db0a2b80167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc08f351-e66b-4972-b99f-370e204452e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv/lib/python3.8/site-packages/xarray/backends/cfgrib_.py:27: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n",
      "2022-02-22 11:34:22.212967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import os\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "sys.path.insert(0, '../../src')\n",
    "from utils import df_to_xarray,read_xarray,inverse_scale_image, get_point_prediction\n",
    "\n",
    "sys.path.insert(0, '../../src/preprocess')\n",
    "from data_preprocess import preprocess_image_reduced,preprocess_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f90026-6b1f-4845-ae55-92ab9fa7f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as kb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def custom_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    custom_rmse(y_true, y_pred)\n",
    "    calculates root square mean value with focusing only on the ocean\n",
    "    \"\"\"\n",
    "    y_pred = y_pred[y_true != 0]\n",
    "    y_true = y_true[y_true != 0]\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    \n",
    "    return K.sqrt(K.mean(tf.math.squared_difference(y_pred, y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa76e31-8a91-4d1d-80a2-f6ba2af5ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv/lib/python3.8/site-packages/xarray/backends/plugins.py:61: RuntimeWarning: Engine 'cfgrib' loading failed:\n",
      "ecCodes library not found using ['eccodes', 'libeccodes.so', 'libeccodes']\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "dir_name=\"../../data/data1\"\n",
    "val_dir_name=\"../../data/data2\"\n",
    "\n",
    "data,pco2 = preprocess_images(dir_name)\n",
    "data_socat, pco2_socat = preprocess_images(dir_name, socat = True)\n",
    "\n",
    "val_data,val_pco2 = preprocess_images(val_dir_name,\"035\")\n",
    "val_data_socat,val_pco2_socat = preprocess_images(val_dir_name,\"035\",socat=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aded6aa-7f8a-4ee4-bfb4-733afc59f8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 360, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE=data_socat[0].shape\n",
    "OUTPUT_SHAPE=pco2_socat[0].shape\n",
    "\n",
    "INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02da5eec-aded-4053-bf96-16acc9f445bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Reshape, Conv2D, MaxPool2D , Flatten, Input\n",
    "\n",
    "base_model = tf.keras.models.load_model('../../models/base_model/base_model_new.h5', custom_objects={'custom_rmse':custom_rmse})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cfc7bb2-7b6c-4e59-87b4-c7694597e960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1554a433d640>\n",
      "1 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1554a4337c10>\n",
      "2 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x1554a4337850>\n",
      "3 <tensorflow.python.keras.layers.core.Dropout object at 0x1554c033a430>\n",
      "4 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1554a433d7c0>\n",
      "5 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1554a433d6d0>\n",
      "6 <tensorflow.python.keras.layers.convolutional.UpSampling2D object at 0x1554a433d1c0>\n",
      "7 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1554a4331550>\n",
      "8 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1554c047e760>\n",
      "9 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x1554a4342fd0>\n",
      "10 <tensorflow.python.keras.layers.core.Reshape object at 0x1554a43598b0>\n"
     ]
    }
   ],
   "source": [
    "for index, layer in enumerate(base_model.layers):\n",
    "    print(index, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d73e3221-9a19-489d-b8e5-d984254c0240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 360, 64)      8064      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 180, 360, 64)      102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 60, 120, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 120, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 120, 128)      204928    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 120, 128)      409728    \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 180, 360, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 180, 360, 64)      204864    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 180, 360, 2)       3202      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 180, 360, 1)       3         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 180, 360)          0         \n",
      "=================================================================\n",
      "Total params: 933,253\n",
      "Trainable params: 822,725\n",
      "Non-trainable params: 110,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers[:-7]:\n",
    "    layer.trainable = False\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "351723aa-8bdf-45ed-a14f-331495941d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(\n",
    "    loss=custom_rmse, optimizer=keras.optimizers.Adam(learning_rate=0.03),\n",
    ")\n",
    "\n",
    "model_path=\"../../models/transfer_CNN.h5\"\n",
    "\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e69f77ec-9782-4f9b-957c-a852455e710c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "27/27 [==============================] - 7s 242ms/step - loss: 44.9648 - val_loss: 15.5485\n",
      "Epoch 2/30\n",
      "27/27 [==============================] - 5s 197ms/step - loss: 16.4052 - val_loss: 15.4978\n",
      "Epoch 3/30\n",
      "27/27 [==============================] - 5s 198ms/step - loss: 17.1446 - val_loss: 15.4901\n",
      "Epoch 4/30\n",
      "27/27 [==============================] - 5s 197ms/step - loss: 16.8629 - val_loss: 15.4997\n",
      "Epoch 5/30\n",
      "27/27 [==============================] - 5s 197ms/step - loss: 16.7377 - val_loss: 15.5093\n",
      "Epoch 6/30\n",
      "27/27 [==============================] - 5s 197ms/step - loss: 16.9508 - val_loss: 15.5117\n",
      "Epoch 7/30\n",
      "27/27 [==============================] - 5s 198ms/step - loss: 15.8607 - val_loss: 15.5112\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1554a43daa30>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(\n",
    "    data_socat,\n",
    "    pco2_socat,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    workers=-1,\n",
    "    validation_data=(data_socat, pco2_socat),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e07b86e-3363-4401-af8d-351413263926",
   "metadata": {},
   "source": [
    "### Assessing Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029b67b-3a6a-49d9-a58e-f6d5f2926f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model('../../models/transfer_CNN.h5', custom_objects={'custom_rmse':custom_rmse})\n",
    "\n",
    "predicted_frames=best_model.predict(data,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f963ddb-c976-4b33-97eb-8f4af7567720",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_frames[y==0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedd747b-5fa8-4dc8-92ae-84d5c8252933",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(2, 2,figsize=(12, 6))\n",
    "\n",
    "\n",
    "img=axis[0][0].imshow(np.flipud(predicted_frames[0][1]),cmap=\"coolwarm\", interpolation=\"nearest\")\n",
    "axis[0][0].set_title(\"prediction\")\n",
    "plt.colorbar(img,ax=axis)\n",
    "\n",
    "img1=axis[0][1].imshow(np.flipud(y[0][1]),cmap=\"coolwarm\", interpolation=\"nearest\")\n",
    "axis[0][1].set_title(\"true\")\n",
    "\n",
    "diff=np.flipud(np.squeeze(predicted_frames[0][1]-y[0][1]))\n",
    "img2=axis[1][0].imshow(diff,cmap=\"RdBu\", interpolation=\"nearest\")\n",
    "axis[1][0].set_title(\"residual\")\n",
    "plt.colorbar(img2,ax=axis)\n",
    "\n",
    "\n",
    "img2=axis[1][1].imshow(np.flipud(X[0][1][:,:,5]),cmap=\"coolwarm\", interpolation=\"nearest\")\n",
    "axis[1][1].set_title(\"input: previous pco2\")\n",
    "\n",
    "plt.savefig('../../assets/transfer_nfp.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd5bab-9530-440e-a505-74080c8ffac7",
   "metadata": {},
   "source": [
    "### Inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32025f-4e6f-4582-88c4-bda139d2a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_scale_image_nfp(arr, df):\n",
    "    \"\"\"\n",
    "    inverse_scale_image(arr, df):\n",
    "    - inverses the pco2 scaling\n",
    "    \"\"\"\n",
    "    \n",
    "    old_min = np.nanmin(df)\n",
    "    old_max = np.nanmax(df)\n",
    "    y_pred = arr*(old_max-old_min)/255+old_min\n",
    "    \n",
    "    tmp=np.nan_to_num(df[X_index][1:])\n",
    "    y_true=np.expand_dims(tmp,axis=4)\n",
    "    y_pred[y_true==0]=0\n",
    "    return y_true,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc3a8a4-a4e4-499f-be86-872351599da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chl,mld,sss,sst,u10,fg_co2,xco2,icefrac,patm,pco2 = read_xarray(dir_name)\n",
    "y_true,y_pred=inverse_scale_image_nfp(predicted_frames,pco2.pCO2.data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e3ae4-13d7-46f1-b46a-fc1399b0de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scaled back whole grid RMSE score:\")\n",
    "np.sqrt(np.mean((y_true[:,:1]-y_pred[:,:1])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c43f48-09bf-4a7f-ad57-4131b2589c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
